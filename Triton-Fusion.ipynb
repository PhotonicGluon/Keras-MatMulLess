{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fused Layers in Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/\n",
      "Requirement already satisfied: triton-nightly==3.0.0.post20240626041721 in /home/vscode/.cache/pypoetry/virtualenvs/keras-matmulless-b9IALFmu-py3.10/lib/python3.10/site-packages (3.0.0.post20240626041721)\n",
      "Requirement already satisfied: filelock in /home/vscode/.cache/pypoetry/virtualenvs/keras-matmulless-b9IALFmu-py3.10/lib/python3.10/site-packages (from triton-nightly==3.0.0.post20240626041721) (3.15.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly==3.0.0.post20240626041721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"DISABLE_TORCH_COMPILE\"] = \"true\"\n",
    "os.environ[\"TRITON_PRINT_AUTOTUNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the installed triton version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "\n",
    "assert triton.__version__ == \"3.0.0\", f\"Expected Triton to have a version of 3.0.0, but found {triton.__version__}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other needed stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the autotune config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autotune_config():\n",
    "    return [\n",
    "        triton.Config({}, num_warps=1),\n",
    "        triton.Config({}, num_warps=2),\n",
    "        triton.Config({}, num_warps=4),\n",
    "        triton.Config({}, num_warps=8),\n",
    "        triton.Config({}, num_warps=16),\n",
    "        triton.Config({}, num_warps=32),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Baseline Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the RMSNorm is defined to be\n",
    "$$\n",
    "\\frac{\\mathbf{X}}{\\mathrm{RMS}(\\mathbf{X})}\\odot \\mathbf{G} + \\mathbf{B}\n",
    "$$\n",
    "where $\\mathbf{X}$ is the input tensor, $\\mathbf{G}$ is the 'gain' tensor (gamma in the original LayerNorm paper), and $\\mathbf{B}$ is the bias tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the spec that we will be implementing in Triton. This works for any dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_rms_norm_baseline(x: torch.Tensor, gain, bias, epsilon):\n",
    "    dim = x.shape[-1]\n",
    "    scale = dim**0.5\n",
    "\n",
    "    x_norm = torch.nn.functional.normalize(x, p=2, eps=1e-5, dim=-1) * scale\n",
    "    if gain is not None:\n",
    "        x_norm *= gain\n",
    "    if bias is not None:\n",
    "        x_norm += bias\n",
    "\n",
    "    scale = 127.0 / torch.unsqueeze(torch.max(torch.abs(x_norm), dim=-1).values.clamp_(epsilon), -1)\n",
    "    y = torch.clip(torch.round(x_norm * scale), -128, 127) / scale\n",
    "\n",
    "    return x_norm + (y - x_norm).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Fused Layer Norm with Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to fuse the RMSNorm and the quantization into one layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: N803\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_config(),\n",
    "    key=[\"N\", \"HAS_GAIN\", \"HAS_BIAS\"],\n",
    ")\n",
    "@triton.jit\n",
    "def quant_rms_norm_2d_fwd_kernel(\n",
    "    # fmt: off\n",
    "    # Pointers to arrays\n",
    "    x_ptr, y_ptr, gain_ptr, bias_ptr, rrms_ptr,\n",
    "    # Strides\n",
    "    stride_x_row,  # How much to increase the pointer when moving by 1 row\n",
    "    stride_y_row,\n",
    "    # Some constants\n",
    "    N,        # Number of columns in X\n",
    "    EPSILON,  # To avoid division by zero\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_N: tl.constexpr,\n",
    "    HAS_GAIN: tl.constexpr,\n",
    "    HAS_BIAS: tl.constexpr\n",
    "    # fmt: on\n",
    "):\n",
    "    \"\"\"\n",
    "    Forward kernel.\n",
    "\n",
    "    Performs RMSNorm on ``X``, followed by 8-bit quantization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map the PID to the row of X that should be loaded\n",
    "    pid = tl.program_id(0)\n",
    "    x_ptr += pid * stride_x_row\n",
    "\n",
    "    offsets = tl.arange(0, BLOCK_SIZE_N)\n",
    "    mask = offsets < N\n",
    "    x = tl.load(x_ptr + offsets, mask=mask, other=0.0).to(tl.float32)  # Load in higher precision\n",
    "\n",
    "    # Compute reciprocal root mean square (rrms)\n",
    "    mean_of_squares = tl.sum(x * x, axis=0) / N\n",
    "    rrms = 1 / tl.sqrt(mean_of_squares + EPSILON)\n",
    "    tl.store(rrms_ptr + pid, rrms)  # We add PID since that is the row that the RRMS is corresponding to\n",
    "\n",
    "    # Normalize\n",
    "    x_hat = x * rrms\n",
    "\n",
    "    # Apply gain and bias\n",
    "    y = x_hat\n",
    "\n",
    "    if HAS_GAIN:\n",
    "        gain = tl.load(gain_ptr + offsets, mask=mask).to(tl.float32)\n",
    "        y = y * gain\n",
    "    if HAS_BIAS:\n",
    "        bias = tl.load(bias_ptr + offsets, mask=mask).to(tl.float32)\n",
    "        y = y + bias\n",
    "\n",
    "    # Apply 8-bit quantization\n",
    "    scale = 127.0 / tl.maximum(tl.max(tl.abs(y), 0), EPSILON)\n",
    "    y = tl.extra.cuda.libdevice.round(y * scale)  # TODO: This is CUDA only... can we generalize this?\n",
    "    y = tl.maximum(tl.minimum(y, 127), -128) / scale  # The nested max and min creates the clamp/clip function\n",
    "\n",
    "    # Write output\n",
    "    y_ptr += pid * stride_y_row\n",
    "    tl.store(y_ptr + offsets, y, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the companion function that handles checking and allocation of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: N806, S101\n",
    "def quant_rms_norm_2d_fwd(x: torch.Tensor, gain, bias, epsilon):\n",
    "    \"\"\"\n",
    "    Forward pass.\n",
    "\n",
    "    Performs RMSNorm on ``X``, followed by 8-bit quantization.\n",
    "\n",
    "    Requires CUDA.\n",
    "    \"\"\"\n",
    "\n",
    "    assert x.ndim == 2  # TODO: Support other ndim values?\n",
    "\n",
    "    # Get dimensions\n",
    "    M, N = x.shape\n",
    "\n",
    "    # Validate that the input is OK\n",
    "    assert x.stride(-1) == 1\n",
    "\n",
    "    if gain is not None:\n",
    "        assert gain.shape == (N,)\n",
    "        assert gain.stride(-1) == 1\n",
    "    if bias is not None:\n",
    "        assert bias.shape == (N,)\n",
    "        assert bias.stride(-1) == 1\n",
    "\n",
    "    # Enqueue fused kernel if less than 64KiB per feature\n",
    "    MAX_FUSED_SIZE = 65536 // x.element_size()\n",
    "    BLOCK_SIZE_N = min(MAX_FUSED_SIZE, triton.next_power_of_2(N))\n",
    "    if N > BLOCK_SIZE_N:\n",
    "        raise RuntimeError(\"This layer norm doesn't support feature dim >= 64KiB.\")\n",
    "\n",
    "    # Allocate output\n",
    "    y = torch.empty_like(x, dtype=x.dtype)\n",
    "    rrms = torch.empty((M,), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    # Run the kernel\n",
    "    with torch.cuda.device(x.device.index):\n",
    "        quant_rms_norm_2d_fwd_kernel[(M,)](\n",
    "            # fmt: off\n",
    "            # Pointers to arrays\n",
    "            x, y, gain, bias, rrms,\n",
    "            # Strides\n",
    "            x.stride(0),\n",
    "            y.stride(0),\n",
    "            # Some constants\n",
    "            N,  # Number of columns in X\n",
    "            epsilon,  # To avoid division by zero\n",
    "            # Meta-parameters\n",
    "            BLOCK_SIZE_N,\n",
    "            gain is not None,\n",
    "            bias is not None\n",
    "            # fmt: on\n",
    "        )\n",
    "\n",
    "    # Return stuff\n",
    "    return y, rrms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backward pass of the raw RMSNorm layer is a little more involved than the forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define $\\nabla_\\mathbf{Y}$ to be the gradient of the outputs (i.e., Vector-Jacobian Products (VJP), error signal, or $\\mathrm{d}\\,\\mathrm{out}$), $\\nabla_\\mathbf{X}$ be the required change of $\\mathbf{X}$, and $\\nabla_\\mathbf{G}$ and $\\nabla_\\mathbf{B}$ be defined similarly. Let $\\mathbf{\\hat{X}} = \\frac{\\mathbf{X}}{\\mathrm{RMS}(\\mathbf{X})}$. Then we have\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\nabla_\\mathbf{X} &= \\frac1{\\mathrm{RMS}(\\mathbf{X})} \\left(\\nabla_\\mathbf{Y} \\odot \\mathbf{G} - \\underbrace{\\left(\\frac1N \\mathbf{\\hat{X}} \\cdot \\left(\\nabla_\\mathbf{Y} \\odot \\mathbf{G} \\right) \\right)}_{\\texttt{intermediate\\_const}} \\odot \\mathbf{\\hat{X}}\\right) \\\\\n",
    "    \\nabla_\\mathbf{G} &= \\sum_{i=1}^{N}\\left(\\nabla_\\mathbf{Y} \\odot \\mathbf{\\hat{X}}\\right) & (\\text{sum across rows})\\\\\n",
    "    \\nabla_\\mathbf{B} &= \\sum_{i=1}^{N}\\nabla_\\mathbf{Y} & (\\text{sum across rows})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: N803\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_config(),\n",
    "    key=[\"N\", \"HAS_GAIN\", \"HAS_BIAS\"],\n",
    ")\n",
    "@triton.jit\n",
    "def quant_rms_norm_2d_bwd_kernel(\n",
    "    # fmt: off\n",
    "    # Gradient inputs\n",
    "    grad_output_ptr, dx_ptr, dg_ptr, db_ptr,\n",
    "    # Original inputs\n",
    "    x_ptr, gain_ptr, rrms_ptr,\n",
    "    # Strides\n",
    "    stride_x_row,  # How much to increase the pointer when moving by 1 row\n",
    "    stride_grad_output_row,\n",
    "    stride_dx_row,\n",
    "    # Some constants\n",
    "    M,                 # Number of rows in X\n",
    "    N,                 # Number of columns in X\n",
    "    ROWS_PER_PROGRAM,  # Number of rows of X to compute per program\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_N: tl.constexpr,\n",
    "    HAS_GAIN: tl.constexpr,\n",
    "    HAS_BIAS: tl.constexpr\n",
    "    # fmt: on\n",
    "):\n",
    "    \"\"\"\n",
    "    Backward kernel.\n",
    "\n",
    "    Performs the backward pass of RMSNorm, skipping the quantization step.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map the PID to the elements of `x`, `dx`, `dg`, and `db` that should be computed\n",
    "    pid = tl.program_id(0)\n",
    "    row_start = pid * ROWS_PER_PROGRAM\n",
    "\n",
    "    x_ptr += row_start * stride_x_row\n",
    "    grad_output_ptr += row_start * stride_grad_output_row\n",
    "    dx_ptr += row_start * stride_dx_row\n",
    "\n",
    "    offsets = tl.arange(0, BLOCK_SIZE_N)\n",
    "    mask = offsets < N\n",
    "\n",
    "    # Load gradient array, and prepare gradient and bias output gradient arrays\n",
    "    if HAS_GAIN:\n",
    "        gain = tl.load(gain_ptr + offsets, mask=mask).to(tl.float32)\n",
    "        dg = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n",
    "    if HAS_BIAS:\n",
    "        db = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n",
    "\n",
    "    # Iterate through the rows\n",
    "    row_end = min(row_start + ROWS_PER_PROGRAM, M)\n",
    "    for row in range(row_start, row_end):\n",
    "        # Load data to SRAM\n",
    "        x = tl.load(x_ptr + offsets, mask=mask, other=0.0).to(tl.float32)  # Load in higher precision\n",
    "        grad_output = tl.load(grad_output_ptr + offsets, mask=mask, other=0.0).to(tl.float32)\n",
    "        rrms = tl.load(rrms_ptr + row)  # Load the reciprocal root mean square (rrms)\n",
    "\n",
    "        # Compute `x_hat` and the product of the gradient output with the gain\n",
    "        x_hat = x * rrms\n",
    "\n",
    "        # Apply contributions to the gain and bias gradients\n",
    "        gradient_gain_product = grad_output\n",
    "        if HAS_GAIN:\n",
    "            gradient_gain_product = grad_output * gain\n",
    "            dg += grad_output * x_hat\n",
    "        if HAS_BIAS:\n",
    "            db += grad_output\n",
    "\n",
    "        # Compute `dx`\n",
    "        intermediate_const = tl.sum(x_hat * gradient_gain_product, axis=0) / N\n",
    "        dx = (gradient_gain_product - x_hat * intermediate_const) * rrms\n",
    "\n",
    "        # Write `dx`\n",
    "        tl.store(dx_ptr + offsets, dx, mask=mask)\n",
    "\n",
    "        # Update pointers to move to next row\n",
    "        x_ptr += stride_x_row\n",
    "        grad_output_ptr += stride_grad_output_row\n",
    "        dx_ptr += stride_dx_row\n",
    "\n",
    "    # Once we finished computing all the rows for this program, we can write the final `dg` and `db`\n",
    "    if HAS_GAIN:\n",
    "        tl.store(dg_ptr + pid * N + offsets, dg, mask=mask)\n",
    "    if HAS_BIAS:\n",
    "        tl.store(db_ptr + pid * N + offsets, db, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the companion function that handles checking and allocation of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: N806, S101\n",
    "import math\n",
    "\n",
    "\n",
    "def quant_rms_norm_2d_bwd(grad_output: torch.Tensor, x: torch.Tensor, gain, bias, rrms):\n",
    "    \"\"\"\n",
    "    Backward  pass.\n",
    "\n",
    "    Performs the backward pass of RMSNorm on ``X``.\n",
    "    \"\"\"\n",
    "\n",
    "    assert x.ndim == 2  # TODO: Support other ndim values?\n",
    "\n",
    "    # Get dimensions\n",
    "    M, N = x.shape\n",
    "\n",
    "    # Validate that the input is OK\n",
    "    assert x.stride(-1) == 1\n",
    "    assert grad_output.shape == (M, N)\n",
    "    assert grad_output.stride(-1) == 1\n",
    "\n",
    "    if gain is not None:\n",
    "        assert gain.shape == (N,)\n",
    "        assert gain.stride(-1) == 1\n",
    "    if bias is not None:\n",
    "        assert bias.shape == (N,)\n",
    "        assert bias.stride(-1) == 1\n",
    "\n",
    "    # Enqueue fused kernel if less than 64KiB per feature\n",
    "    MAX_FUSED_SIZE = 65536 // x.element_size()\n",
    "    BLOCK_SIZE_N = min(MAX_FUSED_SIZE, triton.next_power_of_2(N))\n",
    "    if N > BLOCK_SIZE_N:\n",
    "        raise RuntimeError(\"This layer norm doesn't support feature dim >= 64KiB.\")\n",
    "\n",
    "    # Allocate output\n",
    "    multi_processor_count = torch.cuda.get_device_properties(x.device).multi_processor_count\n",
    "\n",
    "    dx = torch.empty_like(x, dtype=x.dtype)\n",
    "    if gain is not None:\n",
    "        # This is temporary as we still need to sum across the rows later\n",
    "        dg_temp = torch.empty((multi_processor_count, N), dtype=torch.float32, device=gain.device)\n",
    "    else:\n",
    "        dg_temp = None\n",
    "    if bias is not None:\n",
    "        db_temp = torch.empty((multi_processor_count, N), dtype=torch.float32, device=bias.device)\n",
    "    else:\n",
    "        db_temp = None\n",
    "\n",
    "    # Run the kernel\n",
    "    # TODO: We could make this faster by using a technique like shown in\n",
    "    #   https://triton-lang.org/main/getting-started/tutorials/05-layer-norm.html#backward-pass\n",
    "    rows_per_program = math.ceil(M / multi_processor_count)\n",
    "    with torch.cuda.device(x.device.index):\n",
    "        quant_rms_norm_2d_bwd_kernel[(multi_processor_count,)](\n",
    "            # fmt: off\n",
    "            # Gradient inputs\n",
    "            grad_output, dx, dg_temp, db_temp,\n",
    "            # Original inputs\n",
    "            x, gain, rrms,\n",
    "            # Strides\n",
    "            x.stride(0),\n",
    "            grad_output.stride(0),\n",
    "            dx.stride(0),\n",
    "            # Some constants\n",
    "            M,\n",
    "            N,\n",
    "            rows_per_program,\n",
    "            # Meta-parameters\n",
    "            BLOCK_SIZE_N,\n",
    "            gain is not None,\n",
    "            bias is not None\n",
    "            # fmt: on\n",
    "        )\n",
    "\n",
    "    # Fix the summing of `dg` and `db`\n",
    "    if gain is not None:\n",
    "        dg = dg_temp.sum(0).to(gain.dtype)\n",
    "    else:\n",
    "        dg = None\n",
    "\n",
    "    if bias is not None:\n",
    "        db = db_temp.sum(0).to(bias.dtype)\n",
    "    else:\n",
    "        db = None\n",
    "\n",
    "    # Return stuff\n",
    "    return dx, dg, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Making the Autograd Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have both the forward and backward pass, we can make a `torch.autograd.Function` that comprises both the forward and backward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantRMSNorm2DFn(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, gain, bias, epsilon=1e-5):\n",
    "        # Run the forward function\n",
    "        y, rrms = quant_rms_norm_2d_fwd(x, gain, bias, epsilon)\n",
    "\n",
    "        # Save tensors for backward pass later\n",
    "        ctx.save_for_backward(x, gain, bias, rrms)\n",
    "\n",
    "        # Return the result of the forward pass\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Retrieve stored tensors\n",
    "        x, gain, bias, rrms = ctx.saved_tensors\n",
    "\n",
    "        # Perform backward pass\n",
    "        dx, dg, db = quant_rms_norm_2d_bwd(grad_output, x, gain, bias, rrms)\n",
    "\n",
    "        # Return the gradients\n",
    "        return dx, dg, db, None  # No gradient for `epsilon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wrap this in a standard function-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_rms_norm_2d_triton(x, gain, bias, epsilon=1e-5):\n",
    "    return QuantRMSNorm2DFn.apply(x, gain, bias, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5f7f750850>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(8192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the tensors used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SHAPE = (10, 10)\n",
    "WEIGHT_SHAPE = (X_SHAPE[-1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(X_SHAPE, device=\"cuda\", requires_grad=True)\n",
    "gain = torch.rand(WEIGHT_SHAPE, device=\"cuda\", requires_grad=True)\n",
    "bias = torch.rand(WEIGHT_SHAPE, device=\"cuda\", requires_grad=True)\n",
    "dy = 0.1 * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the baseline result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5447, 1.7738, 0.3631, 1.1034, 0.7402, 0.8799, 0.3771, 0.8939, 0.5587,\n",
       "         0.6425],\n",
       "        [0.4221, 0.2985, 0.3500, 1.3074, 0.7000, 1.2354, 0.1956, 0.6280, 1.2868,\n",
       "         0.3191],\n",
       "        [0.6747, 1.4522, 0.3545, 1.2235, 0.7318, 0.7776, 0.2630, 1.1892, 0.9834,\n",
       "         0.5717],\n",
       "        [0.4624, 1.3345, 0.3468, 1.2189, 0.6725, 1.0193, 0.7251, 1.0298, 0.8511,\n",
       "         0.7145],\n",
       "        [0.4530, 0.3867, 0.3536, 1.1049, 0.6961, 1.1049, 0.5303, 1.4032, 0.7623,\n",
       "         1.0938],\n",
       "        [0.4230, 0.6294, 0.3508, 1.3104, 0.6913, 1.1350, 0.4850, 1.0009, 0.8151,\n",
       "         0.9493],\n",
       "        [0.9127, 1.2201, 0.3555, 1.0664, 0.6245, 1.0856, 0.3170, 0.8838, 1.1913,\n",
       "         0.9319],\n",
       "        [1.2123, 0.8914, 0.3447, 1.1410, 0.6774, 0.9627, 0.2020, 1.5094, 1.0578,\n",
       "         0.3922],\n",
       "        [1.0413, 1.0617, 0.3369, 1.1536, 0.7350, 0.9188, 0.1327, 1.2965, 0.8269,\n",
       "         1.0005],\n",
       "        [0.8077, 1.3206, 0.3462, 1.1924, 0.6411, 1.1539, 0.2821, 1.6283, 1.0129,\n",
       "         0.1667]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ref = quant_rms_norm_baseline(x, gain, bias, 1e-5)\n",
    "y_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that with the Triton result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.87s; best config selected: num_warps: 8, num_ctas: 1, num_stages: 2, maxnreg: None;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5447, 1.7737, 0.3631, 1.1034, 0.7402, 0.8799, 0.3771, 0.8939, 0.5587,\n",
       "         0.6425],\n",
       "        [0.4221, 0.2985, 0.3500, 1.3074, 0.7000, 1.2354, 0.1956, 0.6280, 1.2868,\n",
       "         0.3191],\n",
       "        [0.6747, 1.4522, 0.3545, 1.2235, 0.7318, 0.7776, 0.2630, 1.1892, 0.9834,\n",
       "         0.5717],\n",
       "        [0.4623, 1.3345, 0.3468, 1.2189, 0.6725, 1.0193, 0.7250, 1.0298, 0.8511,\n",
       "         0.7145],\n",
       "        [0.4530, 0.3867, 0.3535, 1.1048, 0.6961, 1.1048, 0.5303, 1.4032, 0.7623,\n",
       "         1.0938],\n",
       "        [0.4230, 0.6294, 0.3508, 1.3104, 0.6913, 1.1350, 0.4850, 1.0009, 0.8151,\n",
       "         0.9493],\n",
       "        [0.9126, 1.2201, 0.3555, 1.0664, 0.6244, 1.0856, 0.3170, 0.8838, 1.1912,\n",
       "         0.9319],\n",
       "        [1.2123, 0.8914, 0.3447, 1.1409, 0.6774, 0.9627, 0.2020, 1.5094, 1.0578,\n",
       "         0.3922],\n",
       "        [1.0413, 1.0617, 0.3369, 1.1536, 0.7350, 0.9188, 0.1327, 1.2965, 0.8269,\n",
       "         1.0004],\n",
       "        [0.8077, 1.3206, 0.3462, 1.1923, 0.6410, 1.1539, 0.2821, 1.6283, 1.0129,\n",
       "         0.1667]], device='cuda:0', grad_fn=<QuantRMSNorm2DFnBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tri = quant_rms_norm_2d_triton(x, gain, bias, 1e-5)\n",
    "y_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Baseline match\n"
     ]
    }
   ],
   "source": [
    "if torch.allclose(y_tri, y_ref, atol=1e-3):\n",
    "    print(\"✅ Triton and Baseline match\")\n",
    "else:\n",
    "    raise ValueError(\"❌ Triton and Baseline differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the baseline result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0078,  0.0402, -0.0129, -0.0158, -0.0524, -0.0079, -0.0948,  0.1027,\n",
      "          0.1327, -0.0244],\n",
      "        [ 0.0709,  0.0114,  0.0033, -0.0562,  0.0288, -0.0261,  0.0541,  0.0599,\n",
      "          0.0078,  0.1711],\n",
      "        [-0.0591, -0.0919,  0.0141,  0.0313,  0.0295,  0.0317,  0.1106,  0.0467,\n",
      "          0.0569, -0.0939],\n",
      "        [ 0.1088, -0.0116,  0.0183,  0.0447,  0.0171,  0.0080, -0.0127, -0.2264,\n",
      "         -0.0414,  0.1106],\n",
      "        [-0.0454,  0.0199,  0.0118,  0.0671,  0.0293, -0.0350, -0.0588, -0.1081,\n",
      "          0.0319,  0.0749],\n",
      "        [ 0.0250,  0.2641, -0.0211, -0.0775, -0.0381, -0.0242, -0.0157,  0.1250,\n",
      "          0.1453, -0.0887],\n",
      "        [-0.1169,  0.0709,  0.0245,  0.0471,  0.0141,  0.0007,  0.0813,  0.2232,\n",
      "          0.0945, -0.2183],\n",
      "        [-0.0392,  0.2809, -0.0388, -0.0592, -0.0410, -0.1031,  0.0837, -0.0956,\n",
      "          0.0940,  0.0461],\n",
      "        [-0.0417,  0.1409,  0.0034, -0.0495, -0.0641,  0.0404, -0.0203, -0.0187,\n",
      "         -0.2352,  0.1868],\n",
      "        [ 0.1165, -0.0732,  0.0315,  0.0366,  0.0242, -0.0287,  0.0871, -0.1121,\n",
      "          0.0582,  0.0067]], device='cuda:0')\n",
      "tensor([-0.0424,  0.1841,  0.0366, -0.3423, -0.3268, -0.4209, -0.0460, -0.2440,\n",
      "         0.2947,  0.1207], device='cuda:0')\n",
      "tensor([ 0.0756,  0.3781,  0.1735, -0.0483,  0.0105, -0.2859,  0.2894, -0.0417,\n",
      "         0.2777,  0.1915], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y_ref.backward(dy, retain_graph=True)\n",
    "dx_ref, dg_ref, db_ref = [tensor.grad.clone() for tensor in [x, gain, bias]]\n",
    "x.grad, gain.grad, bias.grad = None, None, None  # Reset gradients for use later\n",
    "\n",
    "print(dx_ref)\n",
    "print(dg_ref)\n",
    "print(db_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the Triton result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 0.73s; best config selected: num_warps: 8, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "tensor([[-0.0078,  0.0402, -0.0129, -0.0158, -0.0524, -0.0079, -0.0948,  0.1027,\n",
      "          0.1327, -0.0244],\n",
      "        [ 0.0709,  0.0114,  0.0033, -0.0562,  0.0288, -0.0261,  0.0541,  0.0599,\n",
      "          0.0078,  0.1711],\n",
      "        [-0.0591, -0.0919,  0.0141,  0.0313,  0.0295,  0.0317,  0.1106,  0.0467,\n",
      "          0.0569, -0.0939],\n",
      "        [ 0.1088, -0.0116,  0.0183,  0.0447,  0.0171,  0.0080, -0.0127, -0.2264,\n",
      "         -0.0414,  0.1106],\n",
      "        [-0.0454,  0.0199,  0.0118,  0.0671,  0.0293, -0.0350, -0.0588, -0.1081,\n",
      "          0.0319,  0.0749],\n",
      "        [ 0.0250,  0.2641, -0.0211, -0.0775, -0.0380, -0.0242, -0.0157,  0.1250,\n",
      "          0.1453, -0.0887],\n",
      "        [-0.1169,  0.0709,  0.0245,  0.0471,  0.0141,  0.0007,  0.0813,  0.2232,\n",
      "          0.0945, -0.2183],\n",
      "        [-0.0392,  0.2809, -0.0388, -0.0592, -0.0410, -0.1031,  0.0837, -0.0956,\n",
      "          0.0940,  0.0461],\n",
      "        [-0.0417,  0.1409,  0.0034, -0.0495, -0.0641,  0.0404, -0.0203, -0.0186,\n",
      "         -0.2352,  0.1868],\n",
      "        [ 0.1164, -0.0732,  0.0315,  0.0366,  0.0242, -0.0287,  0.0871, -0.1121,\n",
      "          0.0582,  0.0067]], device='cuda:0')\n",
      "tensor([-0.0424,  0.1841,  0.0366, -0.3423, -0.3268, -0.4209, -0.0460, -0.2440,\n",
      "         0.2947,  0.1207], device='cuda:0')\n",
      "tensor([ 0.0756,  0.3781,  0.1735, -0.0483,  0.0105, -0.2859,  0.2894, -0.0417,\n",
      "         0.2777,  0.1915], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y_tri.backward(dy, retain_graph=True)\n",
    "dx_tri, dg_tri, db_tri = [tensor.grad.clone() for tensor in [x, gain, bias]]\n",
    "\n",
    "print(dx_tri)\n",
    "print(dg_tri)\n",
    "print(db_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Baseline match\n"
     ]
    }
   ],
   "source": [
    "if (\n",
    "    torch.allclose(dx_tri, dx_ref, atol=1e-3)\n",
    "    and torch.allclose(dg_tri, dg_ref, atol=1e-3)\n",
    "    and torch.allclose(db_tri, db_ref, atol=1e-3)\n",
    "):\n",
    "    print(\"✅ Triton and Baseline match\")\n",
    "else:\n",
    "    raise ValueError(\"❌ Triton and Baseline differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform benchmarking for both the forward and backward passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the benchmark configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[256 * i for i in range(1, 17)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[\"baseline\", \"triton\"],  # Label name for the lines\n",
    "        line_names=[\"Baseline\", \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"GB/s\",  # Label name for the y-axis\n",
    "        plot_name=f\"quant-rms-norm-{mode}\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"mode\": mode},\n",
    "    )\n",
    "    for mode in [\"forward\", \"backward\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the actual benchmark tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E731\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, N, provider, mode):\n",
    "    print(f\"Trial when M = {M} and N = {N} for {provider} for {mode} pass\")\n",
    "    x_shape = (M, N)\n",
    "    weight_shape = (N,)\n",
    "\n",
    "    x = torch.rand(x_shape, device=\"cuda\", requires_grad=True)\n",
    "    gain = torch.rand(weight_shape, device=\"cuda\", requires_grad=True)\n",
    "    bias = torch.rand(weight_shape, device=\"cuda\", requires_grad=True)\n",
    "    dy = 0.1 * torch.randn_like(x)\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "\n",
    "    def y_fwd():\n",
    "        if provider == \"baseline\":\n",
    "            return quant_rms_norm_baseline(x, gain, bias, 1e-5)\n",
    "        if provider == \"triton\":\n",
    "            return quant_rms_norm_2d_triton(x, gain, bias, 1e-5)\n",
    "\n",
    "    if mode == \"forward\":\n",
    "        gbps = lambda ms: 2 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, quantiles=quantiles)\n",
    "    else:  # Backward\n",
    "        y = y_fwd()\n",
    "        gbps = lambda ms: 3 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: y.backward(dy, retain_graph=True), quantiles=quantiles, grad_to_none=[x]\n",
    "        )\n",
    "\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "\n",
    "# benchmark.run(print_data=True)  # TODO: Re-enable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nD Fused Layer Norm with Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive method for implementing the nD case is to iterate through the batch dimensions, but *not using Triton to do so*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_rms_norm_triton(x: torch.Tensor, gain, bias, epsilon=1e-5):\n",
    "    x_shape = x.shape\n",
    "\n",
    "    num_stacked_matrices = 1\n",
    "    for i in range(x.ndim - 2):  # The last 2 indices are the matrices\n",
    "        num_stacked_matrices *= x_shape[i]\n",
    "\n",
    "    # Identify the shape of the matrices and vectors that will actually be multiplied\n",
    "    matrix_shape = (x_shape[-2], x_shape[-1])\n",
    "    matrix_stride = x_shape[-2] * x_shape[-1]\n",
    "\n",
    "    # Flatten the input arrays for easier processing\n",
    "    x_flat = x.flatten()\n",
    "\n",
    "    # Determine output size\n",
    "    output_size = 1\n",
    "    for dim in x_shape:\n",
    "        output_size *= dim\n",
    "    output_flat = torch.zeros((output_size,), dtype=x.dtype, device=x.device)\n",
    "\n",
    "    for i in range(num_stacked_matrices):\n",
    "        x_part = x_flat[i * matrix_stride : (i + 1) * matrix_stride].reshape(matrix_shape)\n",
    "        x_quantized = quant_rms_norm_2d_triton(x_part, gain, bias, epsilon=epsilon)\n",
    "        output_flat[i * matrix_stride : (i + 1) * matrix_stride] = x_quantized.flatten()\n",
    "\n",
    "    return output_flat.reshape(x_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5f7f750850>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(8192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the arrays used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SHAPE = (2, 2, 3, 3)\n",
    "WEIGHT_SHAPE = (X_SHAPE[-1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(X_SHAPE, device=\"cuda\", requires_grad=True)\n",
    "gain = torch.rand(WEIGHT_SHAPE, device=\"cuda\", requires_grad=True)\n",
    "bias = torch.rand(WEIGHT_SHAPE, device=\"cuda\", requires_grad=True)\n",
    "dy = 0.1 * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the baseline result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4849, 1.3387, 0.3479],\n",
       "          [0.6399, 1.5333, 0.3381],\n",
       "          [0.8744, 1.0782, 0.3481]],\n",
       "\n",
       "         [[1.1459, 0.5684, 0.3338],\n",
       "          [0.6621, 1.4014, 0.3421],\n",
       "          [1.1625, 0.3845, 0.3387]]],\n",
       "\n",
       "\n",
       "        [[[1.0681, 0.4710, 0.3448],\n",
       "          [0.8912, 0.9202, 0.3478],\n",
       "          [1.1505, 0.3533, 0.3352]],\n",
       "\n",
       "         [[0.7796, 1.2859, 0.3443],\n",
       "          [0.4589, 1.3246, 0.3546],\n",
       "          [0.9526, 0.8401, 0.3450]]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ref = quant_rms_norm_baseline(x, gain, bias, 1e-5)\n",
    "y_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that with the Triton result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4849, 1.3387, 0.3479],\n",
       "          [0.6399, 1.5333, 0.3381],\n",
       "          [0.8744, 1.0781, 0.3481]],\n",
       "\n",
       "         [[1.1458, 0.5684, 0.3338],\n",
       "          [0.6621, 1.4014, 0.3421],\n",
       "          [1.1625, 0.3845, 0.3387]]],\n",
       "\n",
       "\n",
       "        [[[1.0681, 0.4710, 0.3448],\n",
       "          [0.8912, 0.9202, 0.3478],\n",
       "          [1.1504, 0.3533, 0.3352]],\n",
       "\n",
       "         [[0.7796, 1.2859, 0.3443],\n",
       "          [0.4589, 1.3246, 0.3546],\n",
       "          [0.9526, 0.8401, 0.3450]]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tri = quant_rms_norm_triton(x, gain, bias, 1e-5)\n",
    "y_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Baseline match\n"
     ]
    }
   ],
   "source": [
    "if torch.allclose(y_tri, y_ref, atol=1e-3):\n",
    "    print(\"✅ Triton and Baseline match\")\n",
    "else:\n",
    "    raise ValueError(\"❌ Triton and Baseline differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the baseline result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0085,  0.0178, -0.0186],\n",
      "          [ 0.1165, -0.0835,  0.1077],\n",
      "          [-0.1970,  0.2153,  0.0060]],\n",
      "\n",
      "         [[-0.0560,  0.2359, -0.0028],\n",
      "          [ 0.0132, -0.0720,  0.1126],\n",
      "          [-0.0146,  0.1242,  0.0077]]],\n",
      "\n",
      "\n",
      "        [[[-0.0306,  0.2027, -0.0162],\n",
      "          [-0.0180, -0.0123,  0.0308],\n",
      "          [-0.0058,  0.0858, -0.0088]],\n",
      "\n",
      "         [[-0.0069,  0.0215, -0.0265],\n",
      "          [ 0.1045, -0.0269,  0.0047],\n",
      "          [ 0.0100,  0.0439, -0.0486]]]], device='cuda:0')\n",
      "tensor([-0.1674, -0.4186,  0.2886], device='cuda:0')\n",
      "tensor([-0.1007,  0.0516,  0.4106], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y_ref.backward(dy, retain_graph=True)\n",
    "dx_ref, dg_ref, db_ref = [tensor.grad.clone() for tensor in [x, gain, bias]]\n",
    "x.grad, gain.grad, bias.grad = None, None, None  # Reset gradients for use later\n",
    "\n",
    "print(dx_ref)\n",
    "print(dg_ref)\n",
    "print(db_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the Triton result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.52s; best config selected: num_warps: 8, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "tensor([[[[-0.0085,  0.0178, -0.0186],\n",
      "          [ 0.1165, -0.0835,  0.1077],\n",
      "          [-0.1970,  0.2153,  0.0060]],\n",
      "\n",
      "         [[-0.0560,  0.2359, -0.0028],\n",
      "          [ 0.0132, -0.0720,  0.1126],\n",
      "          [-0.0146,  0.1242,  0.0077]]],\n",
      "\n",
      "\n",
      "        [[[-0.0306,  0.2027, -0.0162],\n",
      "          [-0.0180, -0.0123,  0.0308],\n",
      "          [-0.0058,  0.0858, -0.0088]],\n",
      "\n",
      "         [[-0.0069,  0.0215, -0.0265],\n",
      "          [ 0.1045, -0.0269,  0.0047],\n",
      "          [ 0.0100,  0.0439, -0.0486]]]], device='cuda:0')\n",
      "tensor([-0.1674, -0.4186,  0.2886], device='cuda:0')\n",
      "tensor([-0.1007,  0.0516,  0.4106], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y_tri.backward(dy, retain_graph=True)\n",
    "dx_tri, dg_tri, db_tri = [tensor.grad.clone() for tensor in [x, gain, bias]]\n",
    "\n",
    "print(dx_tri)\n",
    "print(dg_tri)\n",
    "print(db_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Baseline match\n"
     ]
    }
   ],
   "source": [
    "if (\n",
    "    torch.allclose(dx_tri, dx_ref, atol=1e-3)\n",
    "    and torch.allclose(dg_tri, dg_ref, atol=1e-3)\n",
    "    and torch.allclose(db_tri, db_ref, atol=1e-3)\n",
    "):\n",
    "    print(\"✅ Triton and Baseline match\")\n",
    "else:\n",
    "    raise ValueError(\"❌ Triton and Baseline differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform benchmarking for both the forward and backward passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the benchmark configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[64 * i for i in range(1, 17)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[\"baseline\", \"triton\"],  # Label name for the lines\n",
    "        line_names=[\"Baseline\", \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"GB/s\",  # Label name for the y-axis\n",
    "        plot_name=f\"quant-rms-norm-{mode}\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"mode\": mode},\n",
    "    )\n",
    "    for mode in [\"forward\", \"backward\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the actual benchmark tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial when shape = (8, 8, 64, 64) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 64, 64) for triton for forward pass\n",
      "Trial when shape = (8, 8, 128, 128) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 128, 128) for triton for forward pass\n",
      "Trial when shape = (8, 8, 192, 192) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 192, 192) for triton for forward pass\n",
      "Trial when shape = (8, 8, 256, 256) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 256, 256) for triton for forward pass\n",
      "Trial when shape = (8, 8, 320, 320) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 320, 320) for triton for forward pass\n",
      "Trial when shape = (8, 8, 384, 384) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 384, 384) for triton for forward pass\n",
      "Trial when shape = (8, 8, 448, 448) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 448, 448) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.71s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 512, 512) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 512, 512) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.72s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 576, 576) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 576, 576) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 1.05s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 640, 640) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 640, 640) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.72s; best config selected: num_warps: 8, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 704, 704) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 704, 704) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.73s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 768, 768) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 768, 768) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.76s; best config selected: num_warps: 4, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 832, 832) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 832, 832) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.81s; best config selected: num_warps: 8, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 896, 896) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 896, 896) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.82s; best config selected: num_warps: 8, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 960, 960) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 960, 960) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 0.82s; best config selected: num_warps: 16, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 1024, 1024) for baseline for forward pass\n",
      "Trial when shape = (8, 8, 1024, 1024) for triton for forward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_fwd_kernel finished after 1.36s; best config selected: num_warps: 16, num_ctas: 1, num_stages: 2, maxnreg: None;\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant-rms-norm-forward:\n",
      "         M       N  Baseline     Triton\n",
      "0     64.0    64.0  3.856874   0.343336\n",
      "1    128.0   128.0  4.563788   1.463600\n",
      "2    192.0   192.0  4.751740   3.333092\n",
      "3    256.0   256.0  4.872565   5.905740\n",
      "4    320.0   320.0  4.875030   8.971292\n",
      "5    384.0   384.0  4.931639  13.424618\n",
      "6    448.0   448.0  4.914157  18.307397\n",
      "7    512.0   512.0  4.946300  23.451780\n",
      "8    576.0   576.0  4.940598  25.280097\n",
      "9    640.0   640.0  4.962563  25.702811\n",
      "10   704.0   704.0  4.961220  26.011127\n",
      "11   768.0   768.0  1.509204  13.952406\n",
      "12   832.0   832.0  1.178238   7.932180\n",
      "13   896.0   896.0  1.200803   8.131429\n",
      "14   960.0   960.0  1.193473   8.027735\n",
      "15  1024.0  1024.0  1.198800   8.004519\n",
      "Trial when shape = (8, 8, 64, 64) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 64, 64) for triton for backward pass\n",
      "Trial when shape = (8, 8, 128, 128) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 128, 128) for triton for backward pass\n",
      "Trial when shape = (8, 8, 192, 192) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 192, 192) for triton for backward pass\n",
      "Trial when shape = (8, 8, 256, 256) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 256, 256) for triton for backward pass\n",
      "Trial when shape = (8, 8, 320, 320) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 320, 320) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.79s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 384, 384) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 384, 384) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.80s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 448, 448) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 448, 448) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.23s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 512, 512) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 512, 512) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.22s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 576, 576) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 576, 576) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.89s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 640, 640) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 640, 640) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.92s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 704, 704) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 704, 704) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.24s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 768, 768) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 768, 768) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.28s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 832, 832) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 832, 832) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.38s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 896, 896) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 896, 896) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.36s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 960, 960) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 960, 960) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.40s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n",
      "Trial when shape = (8, 8, 1024, 1024) for baseline for backward pass\n",
      "Trial when shape = (8, 8, 1024, 1024) for triton for backward pass\n",
      "Triton autotuning for function quant_rms_norm_2d_bwd_kernel finished after 1.41s; best config selected: num_warps: 1, num_ctas: 1, num_stages: 2, maxnreg: None;\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant-rms-norm-backward:\n",
      "         M       N  Baseline    Triton\n",
      "0     64.0    64.0  5.560181  0.382899\n",
      "1    128.0   128.0  6.494715  0.490607\n",
      "2    192.0   192.0  6.766520  0.516447\n",
      "3    256.0   256.0  6.866723  0.526529\n",
      "4    320.0   320.0  6.899650  0.530922\n",
      "5    384.0   384.0  6.936060  0.533998\n",
      "6    448.0   448.0  6.932462  0.535152\n",
      "7    512.0   512.0  6.944825  0.536464\n",
      "8    576.0   576.0  6.952168  0.536423\n",
      "9    640.0   640.0  6.959831  0.537538\n",
      "10   704.0   704.0  4.691201  0.538371\n",
      "11   768.0   768.0  1.567480  0.115704\n",
      "12   832.0   832.0  1.452275  0.115058\n",
      "13   896.0   896.0  1.477793  0.118330\n",
      "14   960.0   960.0  1.583770  0.120107\n",
      "15  1024.0  1024.0  1.478136  0.120103\n"
     ]
    }
   ],
   "source": [
    "# ruff: noqa: E731\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, N, provider, mode):\n",
    "    x_shape = (8, 8, M, N)\n",
    "    weight_shape = (x_shape[-1],)\n",
    "\n",
    "    print(f\"Trial when shape = {x_shape} for {provider} for {mode} pass\")\n",
    "\n",
    "    x = torch.rand(x_shape, device=\"cuda\", requires_grad=True)\n",
    "    gain = torch.rand(weight_shape, device=\"cuda\", requires_grad=True)\n",
    "    bias = torch.rand(weight_shape, device=\"cuda\", requires_grad=True)\n",
    "    dy = 0.1 * torch.randn_like(x)\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "\n",
    "    def y_fwd():\n",
    "        if provider == \"baseline\":\n",
    "            return quant_rms_norm_baseline(x, gain, bias, 1e-5)\n",
    "        if provider == \"triton\":\n",
    "            return quant_rms_norm_triton(x, gain, bias, 1e-5)\n",
    "\n",
    "    if mode == \"forward\":\n",
    "        gbps = lambda ms: 2 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, quantiles=quantiles)\n",
    "    else:  # Backward\n",
    "        y = y_fwd()\n",
    "        gbps = lambda ms: 3 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: y.backward(dy, retain_graph=True), quantiles=quantiles, grad_to_none=[x]\n",
    "        )\n",
    "\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "\n",
    "benchmark.run(show_plots=True, print_data=True)  # TODO: Re-enable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Consider\n",
    "- https://github.com/PhotonicGluon/Keras-MatMulLess/blob/ternary-multiplication-triton/Ternary_Multiplication_in_Triton.ipynb\n",
    "- https://github.com/PhotonicGluon/Keras-MatMulLess/blob/ternary-multiplication/ternary_multiplication/torch_multiplication.py\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{article-info}\n",
    ":avatar: https://avatars.githubusercontent.com/u/25820201?v=4\n",
    ":avatar-link: https://github.com/PhotonicGluon/\n",
    ":author: \"[Ryan Kan](https://github.com/PhotonicGluon/)\"\n",
    ":date: \"Jul 1, 2024\"\n",
    ":read-time: \"{sub-ref}`wordcount-minutes` min read\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is largely inspired by the Keras code example [Imbalanced classification: credit card fraud detection](https://keras.io/examples/structured_data/imbalanced_classification/) by [fchollet](https://twitter.com/fchollet).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img alt=\"Credit Cards\" style=\"width: 75%\" src=\"https://storage.googleapis.com/kaggle-datasets-images/310/684/3503c6c827ca269cc00ffa66f2a9c207/dataset-cover.jpg\">\n",
    "</center>\n",
    "\n",
    "It essential that credit card companies can detect fraudulent transactions using credit cards so that customers are not charged for items that they did not buy. This example looks at the [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) dataset to demonstrate how to train a classification model on data with highly imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using is the [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) dataset. To access it, you will need a Kaggle account.\n",
    "\n",
    "```{button-link} https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    ":color: primary\n",
    ":shadow:\n",
    "\n",
    "Download Data\n",
    "```\n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders over two days, where there are 492 frauds out of 284,807 transactions. The dataset is highly unbalanced &mdash; the fraudulent transactions account for only 0.172% of all transactions. Despite this class imbalance, we will try to create a model that detects fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains only numerical input variables which are the result of a [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) transformation. However, the real features used to generate the original, unmodified dataset are not given; the features given here are the principal components obtained with PCA. The only unchanged columns are `Time` and `Amount`. \n",
    "- The `Time` is the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- The `Amount` is the transaction amount.\n",
    "\n",
    "Our aim is to predict the `Class` label, where `1` reflects a fraudulent transaction and `0` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is saved in the file called `credit-card-fraud.csv` in the folder `data`. We will first vectorize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FILE_NAME = \"data/credit-card-fraud.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "all_targets = []\n",
    "\n",
    "with open(FILE_NAME) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # We will skip the first line, which is the header\n",
    "        if i == 0:\n",
    "            # Skip the header\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue\n",
    "        \n",
    "        # Get the fields of that row\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        \n",
    "        # Print the first line as an example of what features we have\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"Shape of features:\", features.shape)\n",
    "print(\"Shape of targets: \", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ADD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 04:54:25.521767: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 04:54:25.524095: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 04:54:25.554003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-24 04:54:26.349312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Data Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
    "zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "zip_file = ZipFile(zip_path)\n",
    "zip_file.extractall(path=\"data/\")\n",
    "csv_path = \"data/jena_climate_2009_2016.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, usecols=[\"T (degC)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420546</th>\n",
       "      <td>-4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420547</th>\n",
       "      <td>-3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420548</th>\n",
       "      <td>-3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420549</th>\n",
       "      <td>-4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420550</th>\n",
       "      <td>-4.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420551 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T (degC)\n",
       "0          -8.02\n",
       "1          -8.41\n",
       "2          -8.51\n",
       "3          -8.31\n",
       "4          -8.27\n",
       "...          ...\n",
       "420546     -4.05\n",
       "420547     -3.35\n",
       "420548     -3.16\n",
       "420549     -4.23\n",
       "420550     -4.82\n",
       "\n",
       "[420551 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation is recorded every 10 mins, that means 6 times per hour. We will resample one point per hour since no drastic change is expected within 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OBSERVATIONS = 2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>-0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>-2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>-2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>-3.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T (degC)\n",
       "0        13.49\n",
       "1        13.20\n",
       "2        12.91\n",
       "3        13.02\n",
       "4        12.93\n",
       "...        ...\n",
       "2395     -0.98\n",
       "2396     -1.40\n",
       "2397     -2.75\n",
       "2398     -2.89\n",
       "2399     -3.93\n",
       "\n",
       "[2400 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df = df.iloc[-NUM_OBSERVATIONS * 6::6, :].reset_index(drop=True)\n",
    "smaller_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(smaller_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every feature has values with varying ranges, we do normalization to confine feature values to a range of $[0, 1]$ before training a neural network. We do this by subtracting the mean and dividing by the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data_mean = data.mean(axis=0)\n",
    "    data_std = data.std(axis=0)\n",
    "    return (data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.361937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.310577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.259218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.278699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.262760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>-1.200720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>-1.275102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>-1.514189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>-1.538983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>-1.723169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T (degC)\n",
       "0     1.361937\n",
       "1     1.310577\n",
       "2     1.259218\n",
       "3     1.278699\n",
       "4     1.262760\n",
       "...        ...\n",
       "2395 -1.200720\n",
       "2396 -1.275102\n",
       "2397 -1.514189\n",
       "2398 -1.538983\n",
       "2399 -1.723169\n",
       "\n",
       "[2400 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df = normalize(smaller_df)\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the model will be to predict the temperature at the same time of the next day (i.e., 24 time steps in the future) given the past 5 days of data (i.e. 120 time steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUTURE = 24\n",
    "PAST = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.zeros((NUM_OBSERVATIONS - FUTURE - PAST, PAST))\n",
    "for i in range(NUM_OBSERVATIONS - FUTURE - PAST):\n",
    "    X[i, :] = np.array(normalized_df.iloc[i:i + PAST]).squeeze()\n",
    "X = X.reshape(-1, PAST, 1)\n",
    "\n",
    "y = np.array(normalized_df.iloc[PAST+FUTURE:]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave the last few entries for validation, and use the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SPLIT = 0.1\n",
    "train_count = int(len(X) * (1 - VAL_SPLIT))\n",
    "\n",
    "X_train = X[:train_count]\n",
    "X_val = X[train_count:]\n",
    "\n",
    "y_train = y[:train_count]\n",
    "y_val = y[train_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2030, 120, 1)\n",
      "(226, 120, 1)\n",
      "\n",
      "(2030,)\n",
      "(226,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print()\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential(\n",
    "#     layers = [\n",
    "#         keras.layers.Input(shape=(PAST, 1)),\n",
    "#         keras.layers.LSTM(32),\n",
    "#         keras.layers.Dense(1)\n",
    "#     ],\n",
    "#     name=\"LSTM-Model\"\n",
    "# )\n",
    "# model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=25, verbose=1)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "# checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "#     monitor=\"val_loss\",\n",
    "#     filepath=\"models/time-series-forcasting-lstm.keras\",\n",
    "#     verbose=1,\n",
    "#     save_best_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=128,\n",
    "#     shuffle=True,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=[reduce_lr, es_callback, checkpointer]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_best = keras.models.load_model(\"models/time-series-forcasting-lstm.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_best.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"go\", \"rx\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(FUTURE, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (FUTURE + 5) * 2])\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in list(zip(X_val, y_val))[10:10+3]:\n",
    "#     show_plot(\n",
    "#         [x[:, 0], y, model_best.predict(x.reshape(1, PAST, 1))[0]],\n",
    "#         \"Single Step Prediction\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard GRU Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential(\n",
    "#     layers = [\n",
    "#         keras.layers.Input(shape=(PAST, 1)),\n",
    "#         keras.layers.GRU(64),\n",
    "#         keras.layers.Dense(1)\n",
    "#     ],\n",
    "#     name=\"GRU-Model\"\n",
    "# )\n",
    "# model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=25, verbose=1)\n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "# checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "#     monitor=\"val_loss\",\n",
    "#     filepath=\"models/time-series-forcasting-gru.keras\",\n",
    "#     verbose=1,\n",
    "#     save_best_only=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=128,\n",
    "#     shuffle=True,\n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=[reduce_lr, es_callback, checkpointer]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = keras.models.load_model(\"models/time-series-forcasting-gru.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2086668461561203"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in list(zip(X_val, y_val))[10:10+3]:\n",
    "#     show_plot(\n",
    "#         [x[:, 0], y, model_best.predict(x.reshape(1, PAST, 1))[0]],\n",
    "#         \"Single Step Prediction\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU-MML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_mml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GRUMML-Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"GRUMML-Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ grumml (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRUMML</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ grumml (\u001b[38;5;33mGRUMML\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m17,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,409</span> (68.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,409\u001b[0m (68.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,409</span> (68.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,409\u001b[0m (68.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    layers = [\n",
    "        keras.layers.Input(shape=(PAST, 1)),\n",
    "        keras_mml.layers.GRUMML(128, activation=\"tanh\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ],\n",
    "    name=\"GRUMML-Model\"\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=20, verbose=1)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=\"models/time-series-forcasting-grumml.keras\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5463\n",
      "Epoch 1: val_loss improved from inf to 0.36355, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.5312 - val_loss: 0.3635 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3021\n",
      "Epoch 2: val_loss improved from 0.36355 to 0.32478, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3028 - val_loss: 0.3248 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3064\n",
      "Epoch 3: val_loss improved from 0.32478 to 0.32455, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.3057 - val_loss: 0.3245 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2931\n",
      "Epoch 4: val_loss improved from 0.32455 to 0.32275, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2937 - val_loss: 0.3227 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2951\n",
      "Epoch 5: val_loss did not improve from 0.32275\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2954 - val_loss: 0.3229 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2974\n",
      "Epoch 6: val_loss did not improve from 0.32275\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2973 - val_loss: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2997\n",
      "Epoch 7: val_loss did not improve from 0.32275\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2993 - val_loss: 0.3235 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2886\n",
      "Epoch 8: val_loss improved from 0.32275 to 0.32234, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2894 - val_loss: 0.3223 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2884\n",
      "Epoch 9: val_loss improved from 0.32234 to 0.32232, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2892 - val_loss: 0.3223 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2951\n",
      "Epoch 10: val_loss improved from 0.32232 to 0.32080, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2951 - val_loss: 0.3208 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2980\n",
      "Epoch 11: val_loss did not improve from 0.32080\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2977 - val_loss: 0.3237 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3142\n",
      "Epoch 12: val_loss improved from 0.32080 to 0.31914, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.3119 - val_loss: 0.3191 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3053\n",
      "Epoch 13: val_loss did not improve from 0.31914\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3040 - val_loss: 0.3275 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3077\n",
      "Epoch 14: val_loss did not improve from 0.31914\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3061 - val_loss: 0.3194 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2919\n",
      "Epoch 15: val_loss did not improve from 0.31914\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2922 - val_loss: 0.3215 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2946\n",
      "Epoch 16: val_loss did not improve from 0.31914\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2945 - val_loss: 0.3198 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3101\n",
      "Epoch 17: val_loss improved from 0.31914 to 0.31903, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.3081 - val_loss: 0.3190 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3018\n",
      "Epoch 18: val_loss did not improve from 0.31903\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3005 - val_loss: 0.3211 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2929\n",
      "Epoch 19: val_loss did not improve from 0.31903\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2930 - val_loss: 0.3223 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3015\n",
      "Epoch 20: val_loss improved from 0.31903 to 0.31507, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3005 - val_loss: 0.3151 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2896\n",
      "Epoch 21: val_loss did not improve from 0.31507\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2897 - val_loss: 0.3156 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2994\n",
      "Epoch 22: val_loss did not improve from 0.31507\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2983 - val_loss: 0.3218 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2910\n",
      "Epoch 23: val_loss did not improve from 0.31507\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2908 - val_loss: 0.3184 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2792\n",
      "Epoch 24: val_loss improved from 0.31507 to 0.31234, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2803 - val_loss: 0.3123 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2692\n",
      "Epoch 25: val_loss did not improve from 0.31234\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2714 - val_loss: 0.3147 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2761\n",
      "Epoch 26: val_loss did not improve from 0.31234\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2774 - val_loss: 0.3124 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2861\n",
      "Epoch 27: val_loss did not improve from 0.31234\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2863 - val_loss: 0.3239 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2962\n",
      "Epoch 28: val_loss did not improve from 0.31234\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2956 - val_loss: 0.3244 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2978\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.31234\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2966 - val_loss: 0.3138 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2645\n",
      "Epoch 30: val_loss improved from 0.31234 to 0.31180, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2668 - val_loss: 0.3118 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2711\n",
      "Epoch 31: val_loss did not improve from 0.31180\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2727 - val_loss: 0.3134 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2777\n",
      "Epoch 32: val_loss improved from 0.31180 to 0.31095, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2785 - val_loss: 0.3110 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2886\n",
      "Epoch 33: val_loss did not improve from 0.31095\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2881 - val_loss: 0.3117 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2706\n",
      "Epoch 34: val_loss did not improve from 0.31095\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2721 - val_loss: 0.3123 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2879\n",
      "Epoch 35: val_loss did not improve from 0.31095\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2875 - val_loss: 0.3110 - learning_rate: 2.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2844\n",
      "Epoch 36: val_loss did not improve from 0.31095\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2842 - val_loss: 0.3121 - learning_rate: 2.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2901\n",
      "Epoch 37: val_loss improved from 0.31095 to 0.31050, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2894 - val_loss: 0.3105 - learning_rate: 2.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2959\n",
      "Epoch 38: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2944 - val_loss: 0.3113 - learning_rate: 2.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2820\n",
      "Epoch 39: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2821 - val_loss: 0.3110 - learning_rate: 2.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2790\n",
      "Epoch 40: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2795 - val_loss: 0.3108 - learning_rate: 2.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2829\n",
      "Epoch 41: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2829 - val_loss: 0.3109 - learning_rate: 2.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2812\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2814 - val_loss: 0.3109 - learning_rate: 2.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2934\n",
      "Epoch 43: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2921 - val_loss: 0.3107 - learning_rate: 4.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2904\n",
      "Epoch 44: val_loss did not improve from 0.31050\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2894 - val_loss: 0.3106 - learning_rate: 4.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2686\n",
      "Epoch 45: val_loss improved from 0.31050 to 0.31049, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2702 - val_loss: 0.3105 - learning_rate: 4.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2829\n",
      "Epoch 46: val_loss improved from 0.31049 to 0.31034, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2828 - val_loss: 0.3103 - learning_rate: 4.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2790\n",
      "Epoch 47: val_loss did not improve from 0.31034\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2793 - val_loss: 0.3105 - learning_rate: 4.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2817\n",
      "Epoch 48: val_loss did not improve from 0.31034\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2818 - val_loss: 0.3105 - learning_rate: 4.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2691\n",
      "Epoch 49: val_loss did not improve from 0.31034\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2706 - val_loss: 0.3107 - learning_rate: 4.0000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2672\n",
      "Epoch 50: val_loss did not improve from 0.31034\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2690 - val_loss: 0.3105 - learning_rate: 4.0000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2842\n",
      "Epoch 51: val_loss improved from 0.31034 to 0.31015, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.2840 - val_loss: 0.3101 - learning_rate: 4.0000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2887\n",
      "Epoch 52: val_loss improved from 0.31015 to 0.30981, saving model to models/time-series-forcasting-grumml.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.2879 - val_loss: 0.3098 - learning_rate: 4.0000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2829\n",
      "Epoch 53: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2828 - val_loss: 0.3105 - learning_rate: 4.0000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2770\n",
      "Epoch 54: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2776 - val_loss: 0.3101 - learning_rate: 4.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2743\n",
      "Epoch 55: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2753 - val_loss: 0.3106 - learning_rate: 4.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2791\n",
      "Epoch 56: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2794 - val_loss: 0.3100 - learning_rate: 4.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2803\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2805 - val_loss: 0.3101 - learning_rate: 4.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2734\n",
      "Epoch 58: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2744 - val_loss: 0.3101 - learning_rate: 8.0000e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2824\n",
      "Epoch 59: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2824 - val_loss: 0.3101 - learning_rate: 8.0000e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2878\n",
      "Epoch 60: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2871 - val_loss: 0.3101 - learning_rate: 8.0000e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2850\n",
      "Epoch 61: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2846 - val_loss: 0.3100 - learning_rate: 8.0000e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2886\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2878 - val_loss: 0.3101 - learning_rate: 8.0000e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2814\n",
      "Epoch 63: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2814 - val_loss: 0.3101 - learning_rate: 1.6000e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2745\n",
      "Epoch 64: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2754 - val_loss: 0.3101 - learning_rate: 1.6000e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2813\n",
      "Epoch 65: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2813 - val_loss: 0.3101 - learning_rate: 1.6000e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2764\n",
      "Epoch 66: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2770 - val_loss: 0.3101 - learning_rate: 1.6000e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2722\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2733 - val_loss: 0.3101 - learning_rate: 1.6000e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2966\n",
      "Epoch 68: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2949 - val_loss: 0.3101 - learning_rate: 1.0000e-06\n",
      "Epoch 69/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2684\n",
      "Epoch 69: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.2700 - val_loss: 0.3101 - learning_rate: 1.0000e-06\n",
      "Epoch 70/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2839\n",
      "Epoch 70: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2836 - val_loss: 0.3101 - learning_rate: 1.0000e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2781\n",
      "Epoch 71: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2785 - val_loss: 0.3101 - learning_rate: 1.0000e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2756\n",
      "Epoch 72: val_loss did not improve from 0.30981\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2763 - val_loss: 0.3101 - learning_rate: 1.0000e-06\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f21b04d26e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[reduce_lr, es_callback, checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = keras.models.load_model(\"models/time-series-forcasting-grumml.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2620  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30981412529945374"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in list(zip(X_val, y_val))[10:10+3]:\n",
    "#     show_plot(\n",
    "#         [x[:, 0], y, model_best.predict(x.reshape(1, PAST, 1))[0]],\n",
    "#         \"Single Step Prediction\",\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdrF5MIoMXX8"
   },
   "source": [
    "# Ternary Multiplication in Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGNuCpfuMpAU"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/\n",
      "Requirement already satisfied: triton-nightly==3.0.0.post20240626041721 in /home/vscode/.cache/pypoetry/virtualenvs/keras-matmulless-b9IALFmu-py3.10/lib/python3.10/site-packages (3.0.0.post20240626041721)\n",
      "Requirement already satisfied: filelock in /home/vscode/.cache/pypoetry/virtualenvs/keras-matmulless-b9IALFmu-py3.10/lib/python3.10/site-packages (from triton-nightly==3.0.0.post20240626041721) (3.15.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly==3.0.0.post20240626041721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TRITON_PRINT_AUTOTUNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DAdIYpUMjyD"
   },
   "source": [
    "Check the installed triton version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hNPo7UMLMlVY"
   },
   "outputs": [],
   "source": [
    "import triton\n",
    "\n",
    "assert triton.__version__ == \"3.0.0\", f\"Expected Triton to have a version of 3.0.0, but found {triton.__version__}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh04HhvLMznK"
   },
   "source": [
    "Import other needed stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "uglYrA26M0vg"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import torch\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI2dDdjsbPnB"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "mzcLVuDLM30m"
   },
   "outputs": [],
   "source": [
    "def get_current_target():\n",
    "    return triton.runtime.driver.active.get_current_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "57uA2WypcCAR"
   },
   "outputs": [],
   "source": [
    "def is_cuda():\n",
    "    current_target = get_current_target()\n",
    "    if current_target.backend != \"cuda\":\n",
    "        return False\n",
    "\n",
    "    if current_target.arch < 70:  # CUDA compute capacity is below 7.0, which is minimum 'stable' supported by Triton\n",
    "        warnings.warn(\n",
    "            \"Compute capacity of CUDA device is below 7.0. The Triton compilation may fail terribly!\", stacklevel=1\n",
    "        )\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Ternary Multiplication Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the autotune config for the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "flaq-3Gez1dl"
   },
   "outputs": [],
   "source": [
    "def _get_autotune_config_2d():\n",
    "    return [\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_M\": 2,\n",
    "                \"BLOCK_SIZE_N\": 2,\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # return [\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_M\": 256,\n",
    "    #             \"BLOCK_SIZE_N\": 256,\n",
    "    #         },\n",
    "    #         num_stages=4,\n",
    "    #         num_warps=4,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_M\": 128,\n",
    "    #             \"BLOCK_SIZE_N\": 128,\n",
    "    #         },\n",
    "    #         num_stages=4,\n",
    "    #         num_warps=4,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_K\": 128,\n",
    "    #             \"BLOCK_SIZE_N\": 64,\n",
    "    #         },\n",
    "    #         num_stages=4,\n",
    "    #         num_warps=4,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_K\": 64,\n",
    "    #             \"BLOCK_SIZE_N\": 128,\n",
    "    #         },\n",
    "    #         num_stages=4,\n",
    "    #         num_warps=4,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_K\": 128,\n",
    "    #             \"BLOCK_SIZE_N\": 32,\n",
    "    #         },\n",
    "    #         num_stages=4,\n",
    "    #         num_warps=4,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_K\": 32,\n",
    "    #             \"BLOCK_SIZE_N\": 128,\n",
    "    #         },\n",
    "    #         num_stages=4,\n",
    "    #         num_warps=4,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_M\": 64,\n",
    "    #             \"BLOCK_SIZE_N\": 32,\n",
    "    #         },\n",
    "    #         num_stages=5,\n",
    "    #         num_warps=2,\n",
    "    #     ),\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_M\": 32,\n",
    "    #             \"BLOCK_SIZE_N\": 64,\n",
    "    #         },\n",
    "    #         num_stages=5,\n",
    "    #         num_warps=2,\n",
    "    #     )\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "gkI9jzg80Fkt"
   },
   "outputs": [],
   "source": [
    "def get_autotune_config_2d():\n",
    "    if is_cuda():\n",
    "        return _get_autotune_config_2d()\n",
    "    else:\n",
    "        raise ValueError(\"Not on CUDA... can't use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the Triton kernel. The rough pseudocode algorithm is as follows.\n",
    "```python\n",
    "# Do in parallel\n",
    "for n in range(0, N, BLOCK_SIZE_N):\n",
    "    acc = zeros((BLOCK_SIZE_N,), dtype=float32)\n",
    "    for m in range(0, M, BLOCK_SIZE_M):\n",
    "        x_block = x[m : m+BLOCK_SIZE_M]\n",
    "        w_block = w[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N]\n",
    "        \n",
    "        # Since `w` is ternary, we only really care about the sign of the element in the array, and so\n",
    "        # we just need to perform two conditional checks\n",
    "        elems_to_sum = tl.where(w_block > 0, x_block, tl.where(w_block < 0, -x_block, tl.zeros_like(x_block)))\n",
    "        acc += tl.sum(elems_to_sum)  # Sum along the M direction\n",
    "\n",
    "    acc = acc / scale\n",
    "    z[n : n+BLOCK_SIZE_N] = acc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43485/3679571787.py:7: UserWarning: Compute capacity of CUDA device is below 7.0. The Triton compilation may fail terribly!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ruff: noqa: N803, PLR2044\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_config_2d(),\n",
    "    key=[\"M\", \"N\"],\n",
    ")\n",
    "@triton.jit\n",
    "def ternary_mul_2d_kernel(\n",
    "    # Pointers to arrays\n",
    "    x_ptr,\n",
    "    w_ptr,\n",
    "    z_ptr,\n",
    "    # Scaling factor\n",
    "    scale,\n",
    "    # `W` matrix dimensions\n",
    "    M,\n",
    "    N,\n",
    "    # The stride variables represent how much to increase the pointer by when moving by 1 element in a particular\n",
    "    # dimension. E.g. `stride_wm` is how much to increase `w_ptr` by to get the element one row down (the `W` matrix\n",
    "    # has `M` rows).\n",
    "    stride_xm,\n",
    "    stride_wm,\n",
    "    stride_wn,\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_M: tl.constexpr,\n",
    "    BLOCK_SIZE_N: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    Kernel for computing the ternary multiplication\n",
    "        z = xW\n",
    "    `x` has shape `(M,)`, `W` has shape `(M, N)`, and `z` has shape `(N,)`.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Create pointers for the first blocks of `x` and `W`.\n",
    "    # We will advance this pointer as we move in the `M` direction and accumulate.\n",
    "    # - `x_ptrs` is a block of `BLOCK_SIZE_M` pointers\n",
    "    # - `w_ptrs` is a block of pointers with shape `(BLOCK_SIZE_M, BLOCK_SIZE_N)`\n",
    "    pid_0 = tl.program_id(axis=0)\n",
    "\n",
    "    offs_m = tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_n = (pid_0 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N  # Guard against wrong offsets\n",
    "\n",
    "    x_ptrs = x_ptr + offs_m\n",
    "    w_ptrs = w_ptr + (offs_m[:, None] * stride_wm + offs_n[None, :] * stride_wn)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the `z` vector.\n",
    "    # We accumulate into a block of `BLOCK_SIZE_N` elements of FP32 values for higher accuracy.\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n",
    "    for m in range(0, tl.cdiv(M, BLOCK_SIZE_M)):\n",
    "        # Load the next block of `x` and `W`, generate a mask by checking along `M`.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        x = tl.load(x_ptrs, mask=offs_m < M - m * BLOCK_SIZE_M, other=0.0)[:, None]  # Force broadcast to correct shape\n",
    "        w = tl.load(w_ptrs, mask=offs_m[:, None] < M - m * BLOCK_SIZE_M, other=0.0)\n",
    "\n",
    "        # Since `w` is ternary, we only really care about the sign of the element in the array, and so\n",
    "        # we just need to perform two conditional checks\n",
    "        elements_to_sum = tl.where(w > 0, x, tl.where(w < 0, -x, tl.zeros_like(x)))\n",
    "        accumulator = accumulator + tl.sum(elements_to_sum, axis=0)  # Sum along the `M` direction\n",
    "\n",
    "        # Advance the ptrs to the next `M` block.\n",
    "        x_ptrs += BLOCK_SIZE_M * stride_xm\n",
    "        w_ptrs += BLOCK_SIZE_M * stride_wm\n",
    "\n",
    "    z = accumulator / scale  # TODO: Do we want to reduce precision back to FP16?\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output vector `z` with masks.\n",
    "    offs_z = pid_0 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    z_ptrs = z_ptr + offs_z\n",
    "    z_mask = offs_z < N\n",
    "    tl.store(z_ptrs, z, mask=z_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xexLN2Dz0GM7"
   },
   "source": [
    "Create a convenience wrapper function that handles the checks and kernel calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "-MqHjzD30GeM"
   },
   "outputs": [],
   "source": [
    "# ruff: noqa: E731, S101, N806\n",
    "def ternary_mul_2d(x, w, scale):\n",
    "    # Check constraints\n",
    "    assert len(x) == w.shape[0], \"Incompatible dimensions\"\n",
    "    assert x.is_contiguous(), \"x must be contiguous\"\n",
    "    assert x.is_cuda and w.is_cuda\n",
    "\n",
    "    # Get dimensions\n",
    "    M, N = w.shape\n",
    "\n",
    "    # Allocate output\n",
    "    z = torch.empty((N,), device=x.device, dtype=torch.float32)  # TODO: Change precision?\n",
    "\n",
    "    # 1D launch kernel where each block gets its own program\n",
    "    grid = lambda META: (triton.cdiv(N, META[\"BLOCK_SIZE_N\"]),)\n",
    "\n",
    "    # fmt: off\n",
    "    ternary_mul_2d_kernel[grid](\n",
    "        x, w, z,\n",
    "        scale,\n",
    "        M, N,\n",
    "        x.stride(0),\n",
    "        w.stride(0), w.stride(1)\n",
    "    )\n",
    "    # fmt: on\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC4g_Sb8ggMk"
   },
   "source": [
    "Test the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "vX7hI8CV0mFX"
   },
   "outputs": [],
   "source": [
    "X_LEN = 256  # x is the 1D vector\n",
    "W_LEN = 256  # W is the quantized weights matrix\n",
    "W_SIZE = (X_LEN, W_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_QyszNe03Sr",
    "outputId": "fdf97a5a-9589-4856-e2c5-d2765fa244c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff4e975df50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YvvBIRqtgk1r"
   },
   "outputs": [],
   "source": [
    "a = torch.rand(X_LEN, device=\"cuda\", dtype=torch.float32)\n",
    "w = torch.tensor([-1., 0., 1.], device=\"cuda\", dtype=torch.float32)[torch.randint(2, W_SIZE)]\n",
    "scale = torch.rand(1, dtype=torch.float32).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dpUvXBwD05_E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-951.4594, -810.9307, -814.1393, -753.9046, -771.3155, -788.1216,\n",
      "        -772.3747, -750.3213, -766.9465, -775.3512, -796.5271, -740.3124,\n",
      "        -743.4036, -764.6676, -699.1962, -728.9562, -786.4343, -858.7490,\n",
      "        -760.0906, -839.8545, -789.4946, -795.4908, -754.4786, -771.1029,\n",
      "        -783.6049, -834.9073, -931.8519, -694.6861, -695.2032, -707.0848,\n",
      "        -848.7382, -729.0391, -769.3309, -748.5757, -834.0535, -869.5665,\n",
      "        -803.8021, -884.6586, -680.9594, -903.9478, -761.8308, -839.1580,\n",
      "        -803.7127, -718.6333, -751.7179, -751.2381, -769.1642, -787.6885,\n",
      "        -768.6287, -815.1701, -668.5592, -739.2564, -811.2242, -763.2260,\n",
      "        -832.9089, -802.8115, -761.8378, -714.6352, -771.6232, -756.2714,\n",
      "        -863.0844, -838.2726, -721.9910, -765.3901, -799.4003, -860.3110,\n",
      "        -921.7515, -778.2712, -853.6852, -721.2637, -808.6849, -811.3694,\n",
      "        -699.9083, -809.1854, -914.3477, -809.1392, -791.8344, -796.9955,\n",
      "        -751.8312, -731.2245, -900.7673, -829.6279, -696.7488, -814.0972,\n",
      "        -745.0986, -840.6050, -721.4727, -811.9926, -740.4084, -884.6636,\n",
      "        -729.5006, -815.8346, -822.4435, -823.6513, -889.7301, -820.0322,\n",
      "        -752.2415, -840.0404, -703.8918, -815.4541, -686.0480, -681.2137,\n",
      "        -796.1993, -768.0498, -972.2722, -751.6311, -738.8566, -696.0828,\n",
      "        -826.9047, -784.3642, -834.1297, -739.7773, -766.2885, -826.3129,\n",
      "        -737.8804, -797.8938, -796.2531, -852.1828, -639.4240, -891.1442,\n",
      "        -865.8923, -782.4530, -799.7996, -784.1414, -700.7862, -822.1578,\n",
      "        -801.3296, -675.0355, -764.7386, -782.5708, -829.5156, -692.1326,\n",
      "        -787.8448, -693.6796, -846.4279, -744.8901, -801.2891, -837.5233,\n",
      "        -701.9556, -744.2525, -654.8667, -826.9344, -846.3845, -742.9725,\n",
      "        -767.7625, -862.4980, -726.5882, -695.3724, -717.1807, -847.3315,\n",
      "        -773.2690, -727.4025, -759.6781, -827.4999, -836.4473, -683.4453,\n",
      "        -843.7963, -834.5532, -945.6599, -798.1615, -783.8471, -716.9811,\n",
      "        -763.6321, -798.4788, -790.1544, -813.0567, -839.4808, -744.3832,\n",
      "        -754.0511, -744.0473, -864.3831, -862.7405, -753.4977, -863.2749,\n",
      "        -716.7770, -852.2720, -787.9136, -806.1100, -804.4357, -789.5510,\n",
      "        -713.6313, -738.0132, -801.2191, -860.4421, -806.0908, -745.6053,\n",
      "        -838.1174, -839.5273, -714.5489, -857.8897, -793.2915, -807.9446,\n",
      "        -796.9210, -794.3760, -834.6567, -759.6036, -704.5126, -814.5659,\n",
      "        -724.5497, -764.7427, -865.2620, -822.6932, -820.5858, -840.5030,\n",
      "        -819.2311, -816.2524, -741.2001, -815.1117, -804.2134, -787.5126,\n",
      "        -809.6976, -845.8332, -773.0093, -832.2064, -883.6086, -782.1836,\n",
      "        -744.2174, -796.0397, -798.9742, -724.2285, -778.5416, -883.7806,\n",
      "        -762.7258, -765.0425, -815.3953, -745.8015, -841.2291, -722.5185,\n",
      "        -926.7850, -922.4192, -807.0449, -759.0336, -747.6671, -734.6192,\n",
      "        -885.3647, -805.5819, -688.4378, -693.0744, -869.5692, -846.7794,\n",
      "        -788.2941, -791.1606, -773.1097, -861.0558, -719.6265, -776.2618,\n",
      "        -812.7778, -777.9195, -747.3929, -802.8259, -773.2090, -774.7262,\n",
      "        -739.1203, -858.7456, -881.1325, -801.0305], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch_output = torch.matmul(a, w) / scale\n",
    "print(torch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "FyLkFEHg1EPX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-951.4592, -810.9305, -814.1395, -753.9046, -771.3154, -788.1215,\n",
      "        -772.3747, -750.3212, -766.9465, -775.3510, -796.5269, -740.3125,\n",
      "        -743.4037, -764.6675, -699.1959, -728.9561, -786.4342, -858.7488,\n",
      "        -760.0905, -839.8543, -789.4948, -795.4908, -754.4786, -771.1029,\n",
      "        -783.6049, -834.9071, -931.8518, -694.6861, -695.2032, -707.0847,\n",
      "        -848.7383, -729.0392, -769.3309, -748.5757, -834.0536, -869.5666,\n",
      "        -803.8021, -884.6584, -680.9593, -903.9477, -761.8306, -839.1578,\n",
      "        -803.7127, -718.6332, -751.7177, -751.2380, -769.1642, -787.6886,\n",
      "        -768.6287, -815.1699, -668.5591, -739.2564, -811.2241, -763.2257,\n",
      "        -832.9092, -802.8113, -761.8378, -714.6353, -771.6231, -756.2714,\n",
      "        -863.0842, -838.2724, -721.9908, -765.3898, -799.4003, -860.3109,\n",
      "        -921.7516, -778.2714, -853.6851, -721.2638, -808.6847, -811.3694,\n",
      "        -699.9081, -809.1856, -914.3478, -809.1390, -791.8342, -796.9955,\n",
      "        -751.8312, -731.2244, -900.7671, -829.6281, -696.7488, -814.0970,\n",
      "        -745.0984, -840.6046, -721.4727, -811.9924, -740.4082, -884.6632,\n",
      "        -729.5005, -815.8346, -822.4434, -823.6511, -889.7300, -820.0322,\n",
      "        -752.2416, -840.0404, -703.8915, -815.4539, -686.0480, -681.2137,\n",
      "        -796.1992, -768.0497, -972.2723, -751.6309, -738.8564, -696.0826,\n",
      "        -826.9045, -784.3642, -834.1296, -739.7772, -766.2886, -826.3127,\n",
      "        -737.8802, -797.8939, -796.2531, -852.1827, -639.4239, -891.1441,\n",
      "        -865.8925, -782.4529, -799.7996, -784.1414, -700.7862, -822.1578,\n",
      "        -801.3296, -675.0354, -764.7386, -782.5707, -829.5156, -692.1326,\n",
      "        -787.8447, -693.6795, -846.4279, -744.8900, -801.2891, -837.5233,\n",
      "        -701.9556, -744.2524, -654.8667, -826.9344, -846.3844, -742.9722,\n",
      "        -767.7625, -862.4982, -726.5883, -695.3723, -717.1806, -847.3315,\n",
      "        -773.2689, -727.4025, -759.6782, -827.4998, -836.4472, -683.4453,\n",
      "        -843.7961, -834.5533, -945.6597, -798.1612, -783.8469, -716.9810,\n",
      "        -763.6321, -798.4789, -790.1545, -813.0565, -839.4808, -744.3832,\n",
      "        -754.0509, -744.0471, -864.3832, -862.7405, -753.4976, -863.2746,\n",
      "        -716.7770, -852.2719, -787.9134, -806.1099, -804.4355, -789.5510,\n",
      "        -713.6315, -738.0133, -801.2192, -860.4420, -806.0908, -745.6051,\n",
      "        -838.1176, -839.5271, -714.5489, -857.8897, -793.2914, -807.9445,\n",
      "        -796.9208, -794.3760, -834.6565, -759.6036, -704.5125, -814.5659,\n",
      "        -724.5496, -764.7428, -865.2617, -822.6931, -820.5857, -840.5029,\n",
      "        -819.2311, -816.2523, -741.2001, -815.1118, -804.2136, -787.5125,\n",
      "        -809.6976, -845.8333, -773.0095, -832.2062, -883.6086, -782.1834,\n",
      "        -744.2172, -796.0399, -798.9742, -724.2285, -778.5416, -883.7808,\n",
      "        -762.7258, -765.0426, -815.3951, -745.8015, -841.2291, -722.5186,\n",
      "        -926.7850, -922.4192, -807.0449, -759.0336, -747.6669, -734.6191,\n",
      "        -885.3645, -805.5820, -688.4377, -693.0744, -869.5690, -846.7791,\n",
      "        -788.2939, -791.1606, -773.1097, -861.0559, -719.6265, -776.2619,\n",
      "        -812.7776, -777.9196, -747.3929, -802.8257, -773.2090, -774.7263,\n",
      "        -739.1203, -858.7456, -881.1324, -801.0305], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "triton_output = ternary_mul_2d(a, w, scale)\n",
    "print(triton_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match\n"
     ]
    }
   ],
   "source": [
    "if torch.allclose(triton_output, torch_output, atol=1e-3):\n",
    "    print(\"✅ Triton and Torch match\")\n",
    "else:\n",
    "    raise ValueError(\"❌ Triton and Torch differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark the Triton kernel against the standard Torch implementation of matmul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF_LIB = \"cuBLAS\"\n",
    "\n",
    "# configs = [\n",
    "#     triton.testing.Benchmark(\n",
    "#         x_names=[\"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "#         x_vals=[128 * i for i in range(1, 31)],  # Different possible values for `x_name`\n",
    "#         line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "#         # Possible values for `line_arg`\n",
    "#         line_vals=[REF_LIB.lower(), \"triton\"],  # Label name for the lines\n",
    "#         line_names=[REF_LIB, \"Triton\"],  # Line styles\n",
    "#         styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "#         ylabel=\"GFLOPS\",  # Label name for the y-axis\n",
    "#         plot_name=\"ternary-mul-2d-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "#         args={},\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# @triton.testing.perf_report(configs)\n",
    "# def benchmark(M, N, provider):\n",
    "#     print(f\"Trial when M = {M} and N = {N} for {provider}\")\n",
    "#     x = torch.rand(M, device=\"cuda\")\n",
    "#     w = torch.tensor([-1.0, 0.0, 1.0], device=\"cuda\")[torch.randint(2, (M, N))]\n",
    "#     scale = torch.rand(1, dtype=torch.float32).item()\n",
    "\n",
    "#     quantiles = [0.5, 0.2, 0.8]\n",
    "#     if provider == REF_LIB.lower():\n",
    "#         ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(x, w) / scale, quantiles=quantiles)\n",
    "#     if provider == \"triton\":\n",
    "#         ms, min_ms, max_ms = triton.testing.do_bench(lambda: ternary_mul_2d(x, w, scale), quantiles=quantiles)\n",
    "#     gflops = lambda ms: 2 * M * N * 1e-9 / (ms * 1e-3)\n",
    "#     return gflops(ms), gflops(max_ms), gflops(min_ms)\n",
    "\n",
    "\n",
    "# benchmark.run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D-2D Ternary Matrix Multipliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_autotune_config_2d2d():\n",
    "    # return [\n",
    "    #     triton.Config(\n",
    "    #         {\n",
    "    #             \"BLOCK_SIZE_K\": 2,\n",
    "    #             \"BLOCK_SIZE_N\": 2,\n",
    "    #         }\n",
    "    #     )\n",
    "    # ]\n",
    "    \n",
    "    return [\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 256,\n",
    "                \"BLOCK_SIZE_N\": 256,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 128,\n",
    "                \"BLOCK_SIZE_N\": 128,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 128,\n",
    "                \"BLOCK_SIZE_N\": 64,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 64,\n",
    "                \"BLOCK_SIZE_N\": 128,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 128,\n",
    "                \"BLOCK_SIZE_N\": 32,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 32,\n",
    "                \"BLOCK_SIZE_N\": 128,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 64,\n",
    "                \"BLOCK_SIZE_N\": 32,\n",
    "            },\n",
    "            num_stages=5,\n",
    "            num_warps=2,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"BLOCK_SIZE_K\": 32,\n",
    "                \"BLOCK_SIZE_N\": 64,\n",
    "            },\n",
    "            num_stages=5,\n",
    "            num_warps=2,\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autotune_config_2d2d():\n",
    "    if is_cuda():\n",
    "        return _get_autotune_config_2d2d()\n",
    "    else:\n",
    "        raise ValueError(\"Not on CUDA... can't use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43485/3679571787.py:7: UserWarning: Compute capacity of CUDA device is below 7.0. The Triton compilation may fail terribly!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ruff: noqa: N803, PLR2044\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_config_2d2d(),\n",
    "    key=[\"K\", \"N\"],\n",
    ")\n",
    "@triton.jit\n",
    "def ternary_mul_2d2d_kernel(\n",
    "    # Pointers to arrays\n",
    "    a_ptr,\n",
    "    w_ptr,\n",
    "    z_ptr,\n",
    "    # Scaling factor\n",
    "    scale,\n",
    "    # Dimensions\n",
    "    K,\n",
    "    M,\n",
    "    N,\n",
    "    # The stride variables represent how much to increase the pointer by when moving by 1 element in a particular\n",
    "    # dimension. E.g. `stride_wm` is how much to increase `w_ptr` by to get the element one row down (the `W` matrix\n",
    "    # has `M` rows).\n",
    "    stride_am,\n",
    "    stride_ak,\n",
    "    stride_wk,\n",
    "    stride_wn,\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_K: tl.constexpr,\n",
    "    BLOCK_SIZE_N: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    Kernel for computing the ternary multiplication\n",
    "        Z = AW\n",
    "    `A` has shape `(M, K)`, `W` has shape `(K, N)`, and `Z` has shape `(M, N)`.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Create pointers for the first blocks of `A` and `W`.\n",
    "    # We will advance this pointer as we move in the `K` direction and accumulate.\n",
    "    # - `a_ptrs` is a block of `BLOCK_SIZE_K` pointers\n",
    "    # - `w_ptrs` is a block of pointers with shape `(BLOCK_SIZE_K, BLOCK_SIZE_N)`\n",
    "    pid_0 = tl.program_id(axis=0)\n",
    "    pid_1 = tl.program_id(axis=1)  # Controls the block of `K`\n",
    "\n",
    "    start_a = pid_0 * stride_am\n",
    "    \n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_n = (pid_1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N  # Guard against wrong offsets\n",
    "\n",
    "    a_ptrs = a_ptr + start_a + offs_k\n",
    "    w_ptrs = w_ptr + (offs_k[:, None] * stride_wk + offs_n[None, :] * stride_wn)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the `Z` vector.\n",
    "    # We accumulate into a block of `BLOCK_SIZE_N` elements of FP32 values for higher accuracy.\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of `A` and `W`, generate a mask by checking along `K`.\n",
    "        # If it is out of bounds, set it to 0\n",
    "        a = tl.load(a_ptrs, mask=offs_k < K - k * BLOCK_SIZE_K, other=0.0)[:, None]  # Force broadcast to correct shape\n",
    "        w = tl.load(w_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        # Since `W` is ternary, we only really care about the sign of the element in the array, and so\n",
    "        # we just need to perform two conditional checks\n",
    "        elements_to_sum = tl.where(w > 0, a, tl.where(w < 0, -a, tl.zeros_like(a)))\n",
    "        accumulator = accumulator + tl.sum(elements_to_sum, axis=0)  # Sum along the `K` direction\n",
    "\n",
    "        # Advance the ptrs to the next `K` block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        w_ptrs += BLOCK_SIZE_K * stride_wk\n",
    "\n",
    "    z = accumulator / scale  # TODO: Do we want to reduce precision back to FP16?\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of `Z` with masks.\n",
    "    start_z = pid_0 * N\n",
    "    offs_z = pid_1 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    z_ptrs = z_ptr + start_z + offs_z\n",
    "    z_mask = offs_z < N\n",
    "    tl.store(z_ptrs, z, mask=z_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ternary_mul_2d2d(a, w, scale):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == w.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    M, K = a.shape\n",
    "    K, N = w.shape\n",
    "\n",
    "    # Allocates output.\n",
    "    z = torch.empty((M, N), device=a.device, dtype=torch.float32)\n",
    "\n",
    "    # 2D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (M, triton.cdiv(N, META[\"BLOCK_SIZE_N\"]))\n",
    "\n",
    "    # fmt: off\n",
    "    ternary_mul_2d2d_kernel[grid](\n",
    "        a, w, z,\n",
    "        scale,\n",
    "        K, M, N,\n",
    "        a.stride(0), a.stride(1),\n",
    "        w.stride(0), w.stride(1),\n",
    "    )\n",
    "    # fmt: on\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC4g_Sb8ggMk"
   },
   "source": [
    "Test the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "vX7hI8CV0mFX"
   },
   "outputs": [],
   "source": [
    "M = 2\n",
    "N = 2\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_QyszNe03Sr",
    "outputId": "fdf97a5a-9589-4856-e2c5-d2765fa244c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff4e975df50>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "YvvBIRqtgk1r"
   },
   "outputs": [],
   "source": [
    "a = torch.rand((M, K), device=\"cuda\", dtype=torch.float32)\n",
    "w = torch.tensor([-1., 0., 1.], device=\"cuda\", dtype=torch.float32)[torch.randint(2, (K, N))]\n",
    "scale = torch.rand(1, dtype=torch.float32).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "dpUvXBwD05_E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0155, -0.9181],\n",
      "        [-0.6339, -0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch_output = torch.matmul(a, w) / scale\n",
    "print(torch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "FyLkFEHg1EPX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 15.19s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 128, num_warps: 4, num_ctas: 1, num_stages: 4, maxnreg: None;\n",
      "tensor([[-2.0155, -0.9181],\n",
      "        [-0.6339, -0.3603]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "triton_output = ternary_mul_2d2d(a, w, scale)\n",
    "print(triton_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match\n"
     ]
    }
   ],
   "source": [
    "if torch.allclose(triton_output, torch_output, atol=1e-3):\n",
    "    print(\"✅ Triton and Torch match\")\n",
    "else:\n",
    "    raise ValueError(\"❌ Triton and Torch differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial when K = 8, M = 128, and N = 128, for cublas\n",
      "Trial when K = 8, M = 128, and N = 128, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 4.72s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 256, and N = 256, for cublas\n",
      "Trial when K = 8, M = 256, and N = 256, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 0.99s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 384, and N = 384, for cublas\n",
      "Trial when K = 8, M = 384, and N = 384, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.06s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 512, and N = 512, for cublas\n",
      "Trial when K = 8, M = 512, and N = 512, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.09s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 640, and N = 640, for cublas\n",
      "Trial when K = 8, M = 640, and N = 640, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.19s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 768, and N = 768, for cublas\n",
      "Trial when K = 8, M = 768, and N = 768, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.26s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 896, and N = 896, for cublas\n",
      "Trial when K = 8, M = 896, and N = 896, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.42s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 1024, and N = 1024, for cublas\n",
      "Trial when K = 8, M = 1024, and N = 1024, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.51s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 1152, and N = 1152, for cublas\n",
      "Trial when K = 8, M = 1152, and N = 1152, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.73s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n",
      "Trial when K = 8, M = 1280, and N = 1280, for cublas\n",
      "Trial when K = 8, M = 1280, and N = 1280, for triton\n",
      "Triton autotuning for function ternary_mul_2d2d_kernel finished after 1.85s; best config selected: BLOCK_SIZE_K: 32, BLOCK_SIZE_N: 64, num_warps: 2, num_ctas: 1, num_stages: 5, maxnreg: None;\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ternary-mul-2d2d-performance:\n",
      "        M       N      cuBLAS     Triton\n",
      "0   128.0   128.0   25.362230  21.333333\n",
      "1   256.0   256.0   93.090908  26.266935\n",
      "2   384.0   384.0  115.200003  28.097561\n",
      "3   512.0   512.0   93.090908  28.845070\n",
      "4   640.0   640.0   91.428569  29.090909\n",
      "5   768.0   768.0   89.912200  29.350318\n",
      "6   896.0   896.0   90.898549  29.377050\n",
      "7  1024.0  1024.0   90.519339  29.467627\n",
      "8  1152.0  1152.0   91.348019  29.538462\n",
      "9  1280.0  1280.0   90.780144  29.663963\n"
     ]
    }
   ],
   "source": [
    "REF_LIB = \"cuBLAS\"\n",
    "K = 8\n",
    "\n",
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[128 * i for i in range(1, 11)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[REF_LIB.lower(), \"triton\"],  # Label name for the lines\n",
    "        line_names=[REF_LIB, \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"GFLOPS\",  # Label name for the y-axis\n",
    "        plot_name=\"ternary-mul-2d2d-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={},\n",
    "    )\n",
    "]\n",
    "\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, N, provider):\n",
    "    print(f\"Trial when K = {K}, M = {M}, and N = {N}, for {provider}\")\n",
    "    a = torch.rand((M, K), device=\"cuda\")\n",
    "    w = torch.tensor([-1.0, 0.0, 1.0], device=\"cuda\")[torch.randint(2, (K, N))]\n",
    "    scale = torch.rand(1, dtype=torch.float32).item()\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == REF_LIB.lower():\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, w) / scale, quantiles=quantiles)\n",
    "    if provider == \"triton\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: ternary_mul_2d2d(a, w, scale), quantiles=quantiles)\n",
    "    gflops = lambda ms: 2 * K * M * N * 1e-9 / (ms * 1e-3)\n",
    "    return gflops(ms), gflops(max_ms), gflops(min_ms)\n",
    "\n",
    "\n",
    "benchmark.run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Ternary Multiplication Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autotune config should be similar to the 2D case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_autotune_config_3d():\n",
    "#     if is_cuda():\n",
    "#         return _get_autotune_config_2d()\n",
    "#     else:\n",
    "#         raise ValueError(\"Not on CUDA... can't use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel's rough pseudocode algorithm is as follows.\n",
    "```python\n",
    "k = 0  # Output vector pointer\n",
    "\n",
    "# Do in parallel\n",
    "for i in range(0, num_elem_per_matrix, matrix_stride):\n",
    "    # Do in parallel\n",
    "    for j in range(0, num_elem_per_vector, vector_stride):\n",
    "        matrix_elements = w_flat[i : i+matrix_stride].reshape(matrix_shape)\n",
    "        vector_elements = x_flat[j : j+vector_stride]\n",
    "        product = _2d_ternary_multiplication(vector_elements, matrix_elements, scale)\n",
    "        output_flat[k : k+output_stride] = product\n",
    "        k += output_stride\n",
    "\n",
    "return output_flat.reshape(output_shape)\n",
    "```\n",
    "\n",
    "Note that `matrix_stride` and `vector_stride` may not be power-of-two values. Thus we will employ padding to ensure that achieve this, but using a mask to ensure that we don't get memory access errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ruff: noqa: N803, PLR2044\n",
    "# @triton.autotune(\n",
    "#     configs=get_autotune_config_3d(),\n",
    "#     key=[\"M\", \"N\"],\n",
    "# )\n",
    "# @triton.jit\n",
    "# def ternary_mul_3d_kernel(\n",
    "#     # Pointers to arrays\n",
    "#     x_ptr,\n",
    "#     w_ptr,\n",
    "#     z_ptr,\n",
    "#     # Scaling factor\n",
    "#     scale,\n",
    "#     # `W` matrix dimensions\n",
    "#     K: tl.constexpr,\n",
    "#     M: tl.constexpr,\n",
    "#     N: tl.constexpr,\n",
    "#     # Strides\n",
    "#     stride_xk,\n",
    "#     stride_xm,\n",
    "#     stride_wk,\n",
    "#     stride_wm,\n",
    "#     stride_wn,\n",
    "#     # Meta-parameters\n",
    "#     BLOCK_SIZE_M: tl.constexpr,\n",
    "#     BLOCK_SIZE_N: tl.constexpr,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Kernel for computing the batched ternary multiplication\n",
    "#         z = xW\n",
    "#     `x` has shape `(K, M)`, `W` has shape `(K, M, N)`, and `z` has shape `(K, K, N)`.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # -----------------------------------------------------------\n",
    "#     # Map `pid` to the correct `x` vector and `W` matrix blocks that we are computing\n",
    "#     pid_0 = tl.program_id(axis=0)\n",
    "#     pid_1 = tl.program_id(axis=1)\n",
    "\n",
    "#     pid_x = pid_1 % K\n",
    "#     pid_w = pid_1 // K\n",
    "\n",
    "#     # ----------------------------------------------------------\n",
    "#     # Create pointers for the `x` vector and `W` matrix\n",
    "#     offs_m = tl.arange(0, BLOCK_SIZE_M)\n",
    "#     offs_n = (pid_0 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N  # Guard against wrong offsets\n",
    "\n",
    "#     x_ptrs = x_ptr + pid_x * stride_xk + offs_m\n",
    "#     w_ptrs = w_ptr + pid_w * stride_wk + (offs_m[:, None] * stride_wm + offs_n[None, :] * stride_wn)\n",
    "\n",
    "#     # -----------------------------------------------------------\n",
    "#     # Iterate to compute a block of the `z` vector.\n",
    "#     # We accumulate into a block of `BLOCK_SIZE_N` elements of FP32 values for higher accuracy.\n",
    "#     accumulator = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n",
    "\n",
    "#     for m in range(0, tl.cdiv(M, BLOCK_SIZE_M)):\n",
    "#         # Load the next block of `x` and `W`, generate a mask by checking along `M`.\n",
    "#         # If it is out of bounds, set it to 0.\n",
    "#         x = tl.load(x_ptrs, mask=offs_m < M - m * BLOCK_SIZE_M, other=0.0)[:, None]  # Force broadcast to correct shape\n",
    "#         w = tl.load(w_ptrs, mask=offs_m[:, None] < M - m * BLOCK_SIZE_M, other=0.0)\n",
    "\n",
    "#         # Since `w` is ternary, we only really care about the sign of the element in the array, and so  we just need to\n",
    "#         # perform two conditional checks\n",
    "#         elements_to_sum = tl.where(w > 0, x, tl.where(w < 0, -x, tl.zeros_like(x)))\n",
    "#         accumulator = accumulator + tl.sum(elements_to_sum, axis=0)  # Sum along the `M` direction\n",
    "\n",
    "#         # Advance the ptrs to the next `M` block.\n",
    "#         x_ptrs += BLOCK_SIZE_M * stride_xm\n",
    "#         w_ptrs += BLOCK_SIZE_M * stride_wm\n",
    "\n",
    "#     z = accumulator / scale  # TODO: Do we want to reduce precision back to FP16?\n",
    "\n",
    "#     # -----------------------------------------------------------\n",
    "#     # Write back the block of the output vector `z` with masks\n",
    "#     offs_z = pid_0 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "#     z_ptrs = z_ptr + pid_1 * N + offs_z\n",
    "#     z_mask = offs_z < N\n",
    "#     tl.store(z_ptrs, z, mask=z_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a convenience wrapper function that handles the checks and kernel calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ruff: noqa: E731, S101, N806\n",
    "# def ternary_mul_3d(x, w, scale):\n",
    "#     # Check constraints\n",
    "#     assert w.ndim == 3, \"Weight matrix does not have suitable dimensionality\"\n",
    "#     assert x.shape[-1] == w.shape[-2], \"Incompatible dimensions\"\n",
    "#     assert x.shape[0] == w.shape[0], \"Incompatible batch sizes\"\n",
    "#     assert x.is_contiguous(), \"x must be contiguous\"\n",
    "#     assert x.is_cuda and w.is_cuda\n",
    "\n",
    "#     # Get dimensions\n",
    "#     K, M, N = w.shape\n",
    "\n",
    "#     # Allocate output\n",
    "#     z = torch.zeros((K, K, N), device=x.device)\n",
    "\n",
    "#     # 2D launch kernel\n",
    "#     grid = lambda META: (triton.cdiv(N, META[\"BLOCK_SIZE_N\"]), K * K)\n",
    "\n",
    "#     # fmt: off\n",
    "#     ternary_mul_3d_kernel[grid](\n",
    "#         x, w, z,\n",
    "#         scale,\n",
    "#         K, M, N,\n",
    "#         x.stride(0), x.stride(1), w.stride(0), w.stride(1), w.stride(2)\n",
    "#     )\n",
    "#     # fmt: on\n",
    "\n",
    "#     return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_SHAPE = (3, 5)     # x is the vector\n",
    "# W_SHAPE = (3, 5, 7)  # W is the quantized weights matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvvBIRqtgk1r"
   },
   "outputs": [],
   "source": [
    "# x = torch.rand(X_SHAPE, device=\"cuda\", dtype=torch.float32)\n",
    "# w = torch.tensor([-1., 0., 1.], device=\"cuda\", dtype=torch.float32)[torch.randint(2, W_SHAPE)]\n",
    "# scale = torch.rand(1, dtype=torch.float32).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpUvXBwD05_E"
   },
   "outputs": [],
   "source": [
    "# torch_output = torch.matmul(x, w) / scale\n",
    "# print(torch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyLkFEHg1EPX"
   },
   "outputs": [],
   "source": [
    "# triton_output = ternary_mul_3d(x, w, scale)\n",
    "# print(triton_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.allclose(triton_output, torch_output, atol=1e-3):\n",
    "#     print(\"✅ Triton and Torch match\")\n",
    "# else:\n",
    "#     raise ValueError(\"❌ Triton and Torch differ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark the Triton kernel against the standard Torch implementation of matmul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_lib = \"cuBLAS\"\n",
    "# K = 4\n",
    "\n",
    "# configs = [\n",
    "#     triton.testing.Benchmark(\n",
    "#         x_names=[\"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "#         x_vals=[128 * i for i in range(11, 16)],  # Different possible values for `x_name`\n",
    "#         line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "#         # Possible values for `line_arg`\n",
    "#         line_vals=[ref_lib.lower(), \"triton\"],  # Label name for the lines\n",
    "#         line_names=[ref_lib, \"Triton\"],  # Line styles\n",
    "#         styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "#         ylabel=\"GFLOPS\",  # Label name for the y-axis\n",
    "#         plot_name=\"ternary-mul-3d-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "#         args={},\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# @triton.testing.perf_report(configs)\n",
    "# def benchmark(M, N, provider):\n",
    "#     print(f\"Trial when K = {K}, M = {M}, N = {N}, for {provider}\")\n",
    "#     x = torch.rand((K, M), device=\"cuda\")\n",
    "#     w = torch.tensor([-1.0, 0.0, 1.0], device=\"cuda\")[torch.randint(2, (K, M, N))]\n",
    "#     scale = torch.rand(1, dtype=torch.float32).item()\n",
    "\n",
    "#     quantiles = [0.5, 0.2, 0.8]\n",
    "#     if provider == ref_lib.lower():\n",
    "#         ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(x, w) / scale, quantiles=quantiles)\n",
    "#     if provider == \"triton\":\n",
    "#         ms, min_ms, max_ms = triton.testing.do_bench(lambda: ternary_mul_3d(x, w, scale), quantiles=quantiles)\n",
    "#     gflops = lambda ms: 2 * K * M * N * 1e-9 / (ms * 1e-3)\n",
    "#     return gflops(ms), gflops(max_ms), gflops(min_ms)\n",
    "\n",
    "\n",
    "# benchmark.run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Ternary Multiplication Kernel (DOES NOT WORK FOR 4D AND ABOVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autotune config should be similar to the 2D case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_autotune_config():\n",
    "#     if is_cuda():\n",
    "#         return _get_autotune_config_2d()\n",
    "#     else:\n",
    "#         raise ValueError(\"Not on CUDA... can't use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel's rough pseudocode algorithm is as follows.\n",
    "```python\n",
    "k = 0  # Output vector pointer\n",
    "\n",
    "# Do in parallel\n",
    "for i in range(0, num_elem_per_matrix, matrix_stride):\n",
    "    # Do in parallel\n",
    "    for j in range(0, num_elem_per_vector, vector_stride):\n",
    "        matrix_elements = w_flat[i : i+matrix_stride].reshape(matrix_shape)\n",
    "        vector_elements = x_flat[j : j+vector_stride]\n",
    "        product = _2d_ternary_multiplication(vector_elements, matrix_elements, scale)\n",
    "        output_flat[k : k+output_stride] = product\n",
    "        k += output_stride\n",
    "\n",
    "return output_flat.reshape(output_shape)\n",
    "```\n",
    "\n",
    "Note that `matrix_stride` and `vector_stride` may not be power-of-two values. Thus we will employ padding to ensure that achieve this, but using a mask to ensure that we don't get memory access errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ruff: noqa: N803, PLR2044\n",
    "# @triton.autotune(\n",
    "#     configs=get_autotune_config(),\n",
    "#     key=[\"M\", \"N\"],\n",
    "# )\n",
    "# @triton.jit\n",
    "# def ternary_mul_kernel(\n",
    "#     # Pointers to arrays\n",
    "#     x_ptr,\n",
    "#     w_ptr,\n",
    "#     z_ptr,\n",
    "#     # Scaling factor\n",
    "#     scale,\n",
    "#     # # `W` matrix dimensions\n",
    "#     M: tl.constexpr,\n",
    "#     N: tl.constexpr,\n",
    "#     # Strides\n",
    "#     matrix_stride,\n",
    "#     vector_stride,\n",
    "#     stride_xm,\n",
    "#     stride_wm,\n",
    "#     stride_wn,\n",
    "#     # Counts of matrices and vectors\n",
    "#     num_stacked_matrices,\n",
    "#     num_stacked_vectors,\n",
    "#     # Meta-parameters\n",
    "#     BLOCK_SIZE_M: tl.constexpr,\n",
    "#     BLOCK_SIZE_N: tl.constexpr,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Kernel for computing the ternary multiplication\n",
    "#         z = xW\n",
    "#     `x` has shape `(..., M)`, `W` has shape `(..., M, N)`, and `z` has shape `(..., N)`.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # -----------------------------------------------------------\n",
    "#     # Map `pid` to the correct `x` vector and `W` matrix blocks that we are computing\n",
    "#     pid_0 = tl.program_id(axis=0)\n",
    "#     pid_1 = tl.program_id(axis=1)\n",
    "    \n",
    "#     pid_vector = pid_1 % num_stacked_vectors\n",
    "#     pid_matrix = pid_1 // num_stacked_vectors\n",
    "    \n",
    "#     # ----------------------------------------------------------\n",
    "#     # Create pointers for the `x` vector and `W` matrix\n",
    "#     offs_m = tl.arange(0, BLOCK_SIZE_M)\n",
    "#     offs_n = (pid_0 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N  # Guard against wrong offsets\n",
    "\n",
    "#     offs_x = pid_vector * vector_stride + offs_m\n",
    "#     offs_w = pid_matrix * matrix_stride + (offs_m[:, None] * stride_wm + offs_n[None, :] * stride_wn)\n",
    "    \n",
    "#     x_ptrs = x_ptr + offs_x\n",
    "#     w_ptrs = w_ptr + offs_w\n",
    "    \n",
    "#     # -----------------------------------------------------------\n",
    "#     # Iterate to compute a block of the `z` vector.\n",
    "#     # We accumulate into a block of `BLOCK_SIZE_N` elements of FP32 values for higher accuracy.\n",
    "#     accumulator = tl.zeros((BLOCK_SIZE_N,), dtype=tl.float32)\n",
    "\n",
    "#     for m in range(0, tl.cdiv(M, BLOCK_SIZE_M)):\n",
    "#         # Load the next block of `x` and `W`, generate a mask by checking along `M`.\n",
    "#         # If it is out of bounds, set it to 0.\n",
    "#         x = tl.load(x_ptrs, mask=offs_m < M - m * BLOCK_SIZE_M, other=0.0)[:, None]  # Force broadcast to correct shape\n",
    "#         w = tl.load(w_ptrs, mask=offs_m[:, None] < M - m * BLOCK_SIZE_M, other=0.0)\n",
    "\n",
    "#         # Since `w` is ternary, we only really care about the sign of the element in the array, and so  we just need to\n",
    "#         # perform two conditional checks\n",
    "#         elements_to_sum = tl.where(w > 0, x, tl.where(w < 0, -x, tl.zeros_like(x)))\n",
    "#         accumulator = accumulator + tl.sum(elements_to_sum, axis=0)  # Sum along the `M` direction\n",
    "\n",
    "#         # Advance the ptrs to the next `M` block.\n",
    "#         x_ptrs += BLOCK_SIZE_M * stride_xm\n",
    "#         w_ptrs += BLOCK_SIZE_M * stride_wm\n",
    "\n",
    "#     z = accumulator / scale  # TODO: Do we want to reduce precision back to FP16?\n",
    "\n",
    "#     # -----------------------------------------------------------\n",
    "#     # Write back the block of the output vector `z` with masks\n",
    "#     offs_z = pid_0 * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "#     z_ptrs = z_ptr + pid_1 * N + offs_z\n",
    "#     z_mask = offs_z < N\n",
    "#     tl.store(z_ptrs, z, mask=z_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a convenience wrapper function that handles the checks and kernel calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ruff: noqa: E731, S101, N806\n",
    "# def ternary_mul(x, w, scale):\n",
    "#     # Check constraints\n",
    "#     assert x.ndim == w.ndim - 1, \"Incompatible dimensionality\"\n",
    "#     assert x.shape[-1] == w.shape[-2], \"Incompatible dimensions\"\n",
    "#     assert x.is_contiguous(), \"x must be contiguous\"\n",
    "\n",
    "#     assert x.is_cuda and w.is_cuda\n",
    "\n",
    "#     # Otherwise, we need to treat what we have as a stack of matrices.\n",
    "#     # First we get the number of stacked matrices and vectors that we need to process\n",
    "#     w_shape = w.shape\n",
    "#     x_shape = x.shape\n",
    "\n",
    "#     num_stacked_matrices = 1\n",
    "#     num_stacked_vectors = 1\n",
    "#     for i in range(w.ndim - 2):  # The last 2 indices are the matrices\n",
    "#         num_stacked_matrices *= w_shape[i]\n",
    "#         num_stacked_vectors *= x_shape[i]\n",
    "\n",
    "#     # Identify the shape of the matrices and vectors that will actually be multiplied\n",
    "#     matrix_shape = (w_shape[-2], w_shape[-1])\n",
    "#     matrix_stride = w_shape[-2] * w_shape[-1]\n",
    "#     vector_stride = x_shape[-1]\n",
    "    \n",
    "#     # Get dimensions\n",
    "#     M, N = w_shape[-2], w_shape[-1]\n",
    "\n",
    "#     # Determine output size and shape\n",
    "#     if w.ndim == 2:\n",
    "#         output_shape = [w_shape[-1]]\n",
    "#         num_processes = 1  # No need for 2D launch grid\n",
    "#     else:\n",
    "#         output_shape = [*list(w_shape[:-2]), x_shape[-2], w_shape[-1]]\n",
    "#         num_processes = num_stacked_matrices * x_shape[-2]\n",
    "#     output = torch.zeros(output_shape, device=x.device)\n",
    "    \n",
    "#     # 2D launch kernel\n",
    "#     grid = lambda META: (triton.cdiv(N, META[\"BLOCK_SIZE_N\"]), num_processes)\n",
    "    \n",
    "#     # fmt: off\n",
    "#     ternary_mul_kernel[grid](\n",
    "#         x, w, output,\n",
    "#         scale,\n",
    "#         M, N,\n",
    "#         matrix_stride, vector_stride, x.stride(-1), w.stride(-2), w.stride(-1),\n",
    "#         num_stacked_matrices, num_stacked_vectors\n",
    "#     )\n",
    "#     # fmt: on\n",
    "\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC4g_Sb8ggMk"
   },
   "source": [
    "Test the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vX7hI8CV0mFX"
   },
   "outputs": [],
   "source": [
    "# # X_SHAPE = (   3, 3, 1)  # x is the vector\n",
    "# # W_SHAPE = (3, 3, 1, 2)  # W is the quantized weights matrix\n",
    "# X_SHAPE = (3, 1)  # x is the vector\n",
    "# W_SHAPE = (3, 1, 2)  # W is the quantized weights matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvvBIRqtgk1r"
   },
   "outputs": [],
   "source": [
    "# x = torch.rand(X_SHAPE, device=\"cuda\", dtype=torch.float32)\n",
    "# w = torch.tensor([-1., 0., 1.], device=\"cuda\", dtype=torch.float32)[torch.randint(2, W_SHAPE)]\n",
    "# scale = torch.rand(1, dtype=torch.float32).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpUvXBwD05_E"
   },
   "outputs": [],
   "source": [
    "# torch_output = torch.matmul(x, w) / scale\n",
    "# print(torch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyLkFEHg1EPX"
   },
   "outputs": [],
   "source": [
    "# triton_output = ternary_mul(x, w, scale)\n",
    "# print(triton_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.allclose(triton_output, torch_output, atol=1e-3):\n",
    "#     print(\"✅ Triton and Torch match\")\n",
    "# else:\n",
    "#     raise ValueError(\"❌ Triton and Torch differ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_lib = \"cuBLAS\"\n",
    "# K = 8\n",
    "\n",
    "# configs = [\n",
    "#     triton.testing.Benchmark(\n",
    "#         x_names=[\"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "#         x_vals=[128 * i for i in range(1, 11)],  # Different possible values for `x_name`\n",
    "#         line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "#         # Possible values for `line_arg`\n",
    "#         line_vals=[ref_lib.lower(), \"triton\"],  # Label name for the lines\n",
    "#         line_names=[ref_lib, \"Triton\"],  # Line styles\n",
    "#         styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "#         ylabel=\"GFLOPS\",  # Label name for the y-axis\n",
    "#         plot_name=\"ternary-mul-general-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "#         args={},\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# @triton.testing.perf_report(configs)\n",
    "# def benchmark(M, N, provider):\n",
    "#     print(f\"Trial when K = {K}, M = {M}, N = {N}, for {provider}\")\n",
    "#     x = torch.rand((K, M), device=\"cuda\")\n",
    "#     w = torch.tensor([-1.0, 0.0, 1.0], device=\"cuda\")[torch.randint(2, (K, M, N))]\n",
    "#     scale = torch.rand(1, dtype=torch.float32).item()\n",
    "\n",
    "#     quantiles = [0.5, 0.2, 0.8]\n",
    "#     if provider == ref_lib.lower():\n",
    "#         ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(x, w) / scale, quantiles=quantiles)\n",
    "#     if provider == \"triton\":\n",
    "#         ms, min_ms, max_ms = triton.testing.do_bench(lambda: ternary_mul(x, w, scale), quantiles=quantiles)\n",
    "#     gflops = lambda ms: 2 * K * M * N * 1e-9 / (ms * 1e-3)\n",
    "#     return gflops(ms), gflops(max_ms), gflops(min_ms)\n",
    "\n",
    "\n",
    "# benchmark.run(show_plots=True, print_data=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
